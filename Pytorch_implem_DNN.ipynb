{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"prepared_stock_data\"\n",
    "# for i, stock in enumerate(listdir(folder)):\n",
    "#     try:\n",
    "#         if i == 0:\n",
    "#             data = pd.read_csv(folder + \"//\" + stock)\n",
    "#         else:\n",
    "#             data = data.append(pd.read_csv(folder + \"//\" + stock))\n",
    "#     except:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"stocks_prepared_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"stocks_prepared_dataset.csv\").drop([\"Unnamed: 0\",\"Name\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>...</th>\n",
       "      <th>T23</th>\n",
       "      <th>T24</th>\n",
       "      <th>T25</th>\n",
       "      <th>T26</th>\n",
       "      <th>T27</th>\n",
       "      <th>T28</th>\n",
       "      <th>T29</th>\n",
       "      <th>T30</th>\n",
       "      <th>T31</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-16</td>\n",
       "      <td>1.250608</td>\n",
       "      <td>1.247874</td>\n",
       "      <td>1.109464</td>\n",
       "      <td>1.104664</td>\n",
       "      <td>1.635328</td>\n",
       "      <td>1.627841</td>\n",
       "      <td>1.720588</td>\n",
       "      <td>1.773613</td>\n",
       "      <td>1.794562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.300995</td>\n",
       "      <td>1.111872</td>\n",
       "      <td>0.991389</td>\n",
       "      <td>0.631393</td>\n",
       "      <td>0.768642</td>\n",
       "      <td>0.216305</td>\n",
       "      <td>0.093381</td>\n",
       "      <td>0.089517</td>\n",
       "      <td>0.029494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-12-17</td>\n",
       "      <td>1.208991</td>\n",
       "      <td>1.072976</td>\n",
       "      <td>1.068259</td>\n",
       "      <td>1.589744</td>\n",
       "      <td>1.582386</td>\n",
       "      <td>1.673529</td>\n",
       "      <td>1.725637</td>\n",
       "      <td>1.746224</td>\n",
       "      <td>1.849530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.208991</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>0.938166</td>\n",
       "      <td>0.608850</td>\n",
       "      <td>0.607427</td>\n",
       "      <td>0.172903</td>\n",
       "      <td>0.095181</td>\n",
       "      <td>0.027119</td>\n",
       "      <td>-0.023631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-12-18</td>\n",
       "      <td>1.068415</td>\n",
       "      <td>1.063709</td>\n",
       "      <td>1.584046</td>\n",
       "      <td>1.576705</td>\n",
       "      <td>1.667647</td>\n",
       "      <td>1.719640</td>\n",
       "      <td>1.740181</td>\n",
       "      <td>1.843260</td>\n",
       "      <td>1.949593</td>\n",
       "      <td>...</td>\n",
       "      <td>1.119159</td>\n",
       "      <td>1.169856</td>\n",
       "      <td>0.837893</td>\n",
       "      <td>0.609583</td>\n",
       "      <td>0.587052</td>\n",
       "      <td>0.169568</td>\n",
       "      <td>0.079762</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>1.026166</td>\n",
       "      <td>1.537037</td>\n",
       "      <td>1.529830</td>\n",
       "      <td>1.619118</td>\n",
       "      <td>1.670165</td>\n",
       "      <td>1.690332</td>\n",
       "      <td>1.791536</td>\n",
       "      <td>1.895935</td>\n",
       "      <td>1.948675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058960</td>\n",
       "      <td>1.083041</td>\n",
       "      <td>0.719112</td>\n",
       "      <td>0.614687</td>\n",
       "      <td>0.515745</td>\n",
       "      <td>0.130794</td>\n",
       "      <td>0.099383</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.020352</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>1.508547</td>\n",
       "      <td>1.501420</td>\n",
       "      <td>1.589706</td>\n",
       "      <td>1.640180</td>\n",
       "      <td>1.660121</td>\n",
       "      <td>1.760188</td>\n",
       "      <td>1.863415</td>\n",
       "      <td>1.915563</td>\n",
       "      <td>1.949749</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071765</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.636617</td>\n",
       "      <td>0.587917</td>\n",
       "      <td>0.498723</td>\n",
       "      <td>0.125240</td>\n",
       "      <td>0.100625</td>\n",
       "      <td>0.022055</td>\n",
       "      <td>-0.029217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0.1        T1        T2        T3        T4        T5        T6  \\\n",
       "0   2009-12-16  1.250608  1.247874  1.109464  1.104664  1.635328  1.627841   \n",
       "1   2009-12-17  1.208991  1.072976  1.068259  1.589744  1.582386  1.673529   \n",
       "2   2009-12-18  1.068415  1.063709  1.584046  1.576705  1.667647  1.719640   \n",
       "3   2009-12-21  1.026166  1.537037  1.529830  1.619118  1.670165  1.690332   \n",
       "4   2009-12-22  1.508547  1.501420  1.589706  1.640180  1.660121  1.760188   \n",
       "\n",
       "         T7        T8        T9  ...       T23       T24       T25       T26  \\\n",
       "0  1.720588  1.773613  1.794562  ...  1.300995  1.111872  0.991389  0.631393   \n",
       "1  1.725637  1.746224  1.849530  ...  1.208991  1.104167  0.938166  0.608850   \n",
       "2  1.740181  1.843260  1.949593  ...  1.119159  1.169856  0.837893  0.609583   \n",
       "3  1.791536  1.895935  1.948675  ...  1.058960  1.083041  0.719112  0.614687   \n",
       "4  1.863415  1.915563  1.949749  ...  1.071765  0.969799  0.636617  0.587917   \n",
       "\n",
       "        T27       T28       T29       T30       T31  Label  \n",
       "0  0.768642  0.216305  0.093381  0.089517  0.029494    NaN  \n",
       "1  0.607427  0.172903  0.095181  0.027119 -0.023631    NaN  \n",
       "2  0.587052  0.169568  0.079762  0.010022 -0.019459    NaN  \n",
       "3  0.515745  0.130794  0.099383 -0.004472 -0.020352    NaN  \n",
       "4  0.498723  0.125240  0.100625  0.022055 -0.029217    NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247620, 33) (124695, 33)\n"
     ]
    }
   ],
   "source": [
    "START = \"2017-01-01\"\n",
    "MIDDLE = \"2019-01-01\"\n",
    "END = \"2020-01-01\"\n",
    "training_data = data[(data[\"Unnamed: 0.1\"] >= START) & (data[\"Unnamed: 0.1\"] < MIDDLE)]\n",
    "testing_data = data[(data[\"Unnamed: 0.1\"] >= MIDDLE) & (data[\"Unnamed: 0.1\"] < END)]\n",
    "print(training_data.shape, testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247510, 33) (124522, 33)\n"
     ]
    }
   ],
   "source": [
    "training_data = training_data.dropna()\n",
    "testing_data = testing_data.dropna()\n",
    "print(training_data.shape, testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>...</th>\n",
       "      <th>T23</th>\n",
       "      <th>T24</th>\n",
       "      <th>T25</th>\n",
       "      <th>T26</th>\n",
       "      <th>T27</th>\n",
       "      <th>T28</th>\n",
       "      <th>T29</th>\n",
       "      <th>T30</th>\n",
       "      <th>T31</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>0.478361</td>\n",
       "      <td>0.468195</td>\n",
       "      <td>0.439730</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.450900</td>\n",
       "      <td>0.432646</td>\n",
       "      <td>0.457089</td>\n",
       "      <td>0.461161</td>\n",
       "      <td>0.423966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.077285</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.026448</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.077693</td>\n",
       "      <td>0.055103</td>\n",
       "      <td>-0.013401</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>0.473238</td>\n",
       "      <td>0.444675</td>\n",
       "      <td>0.440224</td>\n",
       "      <td>0.455884</td>\n",
       "      <td>0.437566</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>0.466180</td>\n",
       "      <td>0.428857</td>\n",
       "      <td>0.430288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241752</td>\n",
       "      <td>0.083765</td>\n",
       "      <td>0.012604</td>\n",
       "      <td>-0.016677</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.072060</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>-0.004183</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>0.460185</td>\n",
       "      <td>0.455686</td>\n",
       "      <td>0.471514</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.477791</td>\n",
       "      <td>0.481921</td>\n",
       "      <td>0.444197</td>\n",
       "      <td>0.445644</td>\n",
       "      <td>0.439557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268440</td>\n",
       "      <td>0.092132</td>\n",
       "      <td>0.027076</td>\n",
       "      <td>-0.009718</td>\n",
       "      <td>0.060875</td>\n",
       "      <td>0.102886</td>\n",
       "      <td>0.088016</td>\n",
       "      <td>-0.043651</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>0.482577</td>\n",
       "      <td>0.498697</td>\n",
       "      <td>0.479841</td>\n",
       "      <td>0.505090</td>\n",
       "      <td>0.509296</td>\n",
       "      <td>0.470876</td>\n",
       "      <td>0.472349</td>\n",
       "      <td>0.466150</td>\n",
       "      <td>0.524863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277158</td>\n",
       "      <td>0.112447</td>\n",
       "      <td>0.050367</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.087621</td>\n",
       "      <td>0.090804</td>\n",
       "      <td>0.150909</td>\n",
       "      <td>0.043986</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>0.490429</td>\n",
       "      <td>0.471677</td>\n",
       "      <td>0.496787</td>\n",
       "      <td>0.500970</td>\n",
       "      <td>0.462761</td>\n",
       "      <td>0.464226</td>\n",
       "      <td>0.458061</td>\n",
       "      <td>0.516451</td>\n",
       "      <td>0.559585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287258</td>\n",
       "      <td>0.110089</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>0.118107</td>\n",
       "      <td>0.089096</td>\n",
       "      <td>0.135571</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.012854</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1        T1        T2        T3        T4        T5        T6  \\\n",
       "1773   2017-01-03  0.478361  0.468195  0.439730  0.435294  0.450900  0.432646   \n",
       "1774   2017-01-04  0.473238  0.444675  0.440224  0.455884  0.437566  0.462094   \n",
       "1775   2017-01-05  0.460185  0.455686  0.471514  0.453000  0.477791  0.481921   \n",
       "1776   2017-01-06  0.482577  0.498697  0.479841  0.505090  0.509296  0.470876   \n",
       "1777   2017-01-09  0.490429  0.471677  0.496787  0.500970  0.462761  0.464226   \n",
       "\n",
       "            T7        T8        T9  ...       T23       T24       T25  \\\n",
       "1773  0.457089  0.461161  0.423966  ...  0.257732  0.077285  0.016667   \n",
       "1774  0.466180  0.428857  0.430288  ...  0.241752  0.083765  0.012604   \n",
       "1775  0.444197  0.445644  0.439557  ...  0.268440  0.092132  0.027076   \n",
       "1776  0.472349  0.466150  0.524863  ...  0.277158  0.112447  0.050367   \n",
       "1777  0.458061  0.516451  0.559585  ...  0.287258  0.110089  0.024725   \n",
       "\n",
       "           T26       T27       T28       T29       T30       T31  Label  \n",
       "1773 -0.026448  0.038003  0.077693  0.055103 -0.013401  0.005061  False  \n",
       "1774 -0.016677  0.028485  0.080895  0.072060 -0.010660 -0.004183   True  \n",
       "1775 -0.009718  0.060875  0.102886  0.088016 -0.043651  0.014208   True  \n",
       "1776  0.002424  0.087621  0.090804  0.150909  0.043986  0.029407   True  \n",
       "1777 -0.007055  0.118107  0.089096  0.135571  0.024326  0.012854  False  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x == False:\n",
    "        return 0\n",
    "    return 1\n",
    "columns = [\"T\"+str(i) for i in range(1,32)]\n",
    "Y_training = training_data['Label'].apply(lambda x: f(x))\n",
    "Y_testing = testing_data['Label'].apply(lambda x: f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.tensor(training_data[columns].values).float()\n",
    "        self.y = torch.tensor(Y_training.values).long()\n",
    "        self.len = self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class TestingData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.tensor(testing_data[columns].values).float()\n",
    "        self.y = torch.tensor(Y_testing.values).long()\n",
    "        self.len = self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Model1(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, D_out=2):\n",
    "        super(DNN_Model1, self).__init__()\n",
    "        self.drop1 = nn.Dropout(p = 0.1)\n",
    "        self.drop2 = nn.Dropout(p = 0.5)\n",
    "        self.channel1_l1 = nn.Linear(D_in, H1)\n",
    "        self.channel1_l2 = nn.Linear(H1, H2)\n",
    "        self.channel1_l3 = nn.Linear(H2, H3)\n",
    "        \n",
    "        self.channel2_l1 = nn.Linear(D_in, H1)\n",
    "        self.channel2_l2 = nn.Linear(H1, H2)\n",
    "        self.channel2_l3 = nn.Linear(H2, H3)\n",
    "        \n",
    "        self.out = nn.Linear(H3, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.max(self.drop1(self.channel1_l1(x)), self.drop1(self.channel2_l1(x)))\n",
    "        x = torch.max(self.drop2(self.channel1_l2(x)), self.drop2(self.channel2_l2(x)))\n",
    "        x = torch.max(self.drop2(self.channel1_l3(x)), self.drop2(self.channel2_l3(x)))\n",
    "        x = F.softmax(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Carlos(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, D_out=2):\n",
    "        super(DNN_Carlos, self).__init__()\n",
    "        self.drop1 = nn.Dropout(p = 0.5)\n",
    "        self.drop2 = nn.Dropout(p = 0.25)\n",
    "        \n",
    "        self.linear1_1 = nn.Linear(D_in, H1)\n",
    "        torch.nn.init.torch.nn.init.xavier_uniform_(self.linear1_1.weight)\n",
    "        self.linear2_1 = nn.Linear(H1, H2)\n",
    "        torch.nn.init.torch.nn.init.xavier_uniform_(self.linear2_1.weight)\n",
    "        self.linear3_1 = nn.Linear(H2, H3)\n",
    "        torch.nn.init.torch.nn.init.xavier_uniform_(self.linear3_1.weight)\n",
    "        self.linear1_2 = nn.Linear(D_in, H1)\n",
    "        torch.nn.init.torch.nn.init.xavier_uniform_(self.linear1_2.weight)\n",
    "        self.linear2_2 = nn.Linear(H1, H2)\n",
    "        torch.nn.init.torch.nn.init.xavier_uniform_(self.linear2_2.weight)\n",
    "        self.linear3_2 = nn.Linear(H2, H3)\n",
    "        torch.nn.init.torch.nn.init.xavier_uniform_(self.linear3_2.weight)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(H1)\n",
    "        self.bn2 = nn.BatchNorm1d(H2)\n",
    "        self.bn3 = nn.BatchNorm1d(H3)\n",
    "        \n",
    "        self.out = nn.Linear(H3, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.max(self.bn1(self.drop1(self.linear1_1(x))), self.bn1(self.drop1(self.linear1_2(x))))\n",
    "        x = torch.max(self.bn2(self.drop2(self.linear2_1(x))), self.bn2(self.drop2(self.linear2_2(x))))\n",
    "        x = torch.max(self.bn3(self.linear3_1(x)), self.bn3(self.linear3_2(x)))\n",
    "        x = F.softmax(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    training_info = {'training_loss':[], 'validation_accuracy': []}\n",
    "    MIN = 9999\n",
    "    COUNTER = 0\n",
    "    temp = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            lambda1 = 0.00001\n",
    "            all_params = torch.cat([b.view(-1) for b in model.parameters()])\n",
    "            l1_regularization = lambda1 * torch.norm(all_params, 1)\n",
    "            loss = criterion(y_hat,y) + l1_regularization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_info['training_loss'].append(loss.data.item())\n",
    "        \n",
    "        if MIN == 9999 or loss.data.item() < MIN or epoch < 400:\n",
    "            MIN = loss.data.item()\n",
    "            COUNTER = 0\n",
    "        else:\n",
    "            COUNTER += 1\n",
    "            \n",
    "        correct = 0\n",
    "        accuracy = 0\n",
    "        for x, y in validation_loader:\n",
    "            z = model(x)\n",
    "            _, y_hat = torch.max(z,1)\n",
    "            correct = (y_hat == y).sum().item()\n",
    "            accuracy += correct/x.shape[0]\n",
    "        training_info['validation_accuracy'].append(accuracy/len(validation_loader))\n",
    "        \n",
    "        if COUNTER == 5:\n",
    "            print(\"FINISHED!!!\")\n",
    "            print(\"LOSS:\",training_info['training_loss'][-1],\"ACCURCY:\",training_info['validation_accuracy'][-1])\n",
    "            print(\"current epoch\",epoch+1,\", \", 100*(epoch+1)/epochs, \"% completed\")\n",
    "            break\n",
    "        \n",
    "        print(\"LOSS:\",training_info['training_loss'][-1],\"ACCURCY:\",training_info['validation_accuracy'][-1])\n",
    "        print(\"current epoch\",epoch+1,\", \", 100*(epoch+1)/epochs, \"% completed\")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMyModel(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    training_info = {'training_loss':[], 'validation_accuracy': []}\n",
    "    MIN = 9999\n",
    "    COUNTER = 0\n",
    "    temp = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_info['training_loss'].append(loss.data.item())\n",
    "            \n",
    "        correct = 0\n",
    "        accuracy = 0\n",
    "        for x, y in validation_loader:\n",
    "            z = model(x)\n",
    "            _, y_hat = torch.max(z,1)\n",
    "            correct = (y_hat == y).sum().item()\n",
    "            accuracy += correct/x.shape[0]\n",
    "        training_info['validation_accuracy'].append(accuracy/len(validation_loader))\n",
    "        \n",
    "        print(\"LOSS:\",training_info['training_loss'][-1],\"ACCURCY:\",training_info['validation_accuracy'][-1])\n",
    "        print(\"current epoch\",epoch+1,\", \", 100*(epoch+1)/epochs, \"% completed\")\n",
    "        \n",
    "    return training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 31\n",
    "hidden1 = 31\n",
    "hidden2 = 10\n",
    "hidden3 = 5\n",
    "out_dim = 2\n",
    "\n",
    "model1 = DNN_Model1(input_dim, hidden1, hidden2, hidden3, out_dim)\n",
    "#model1.to(\"cuda\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TrainingData()\n",
    "testing = TestingData()\n",
    "train_loader = DataLoader(dataset = training, batch_size=2000, shuffle = True)\n",
    "validation_loader = DataLoader(dataset = testing, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs582/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6925956010818481 ACCURCY: 0.51641281910659\n",
      "current epoch 1 ,  0.2 % completed\n",
      "LOSS: 0.6956472992897034 ACCURCY: 0.5236787793011941\n",
      "current epoch 2 ,  0.4 % completed\n",
      "LOSS: 0.691001296043396 ACCURCY: 0.5300445643520567\n",
      "current epoch 3 ,  0.6 % completed\n",
      "LOSS: 0.691961407661438 ACCURCY: 0.5401290614772225\n",
      "current epoch 4 ,  0.8 % completed\n",
      "LOSS: 0.685344934463501 ACCURCY: 0.5516864042459089\n",
      "current epoch 5 ,  1.0 % completed\n",
      "LOSS: 0.6802899837493896 ACCURCY: 0.5639651163202122\n",
      "current epoch 6 ,  1.2 % completed\n",
      "LOSS: 0.6771292090415955 ACCURCY: 0.589405841662981\n",
      "current epoch 7 ,  1.4 % completed\n",
      "LOSS: 0.6833484768867493 ACCURCY: 0.639309668288368\n",
      "current epoch 8 ,  1.6 % completed\n",
      "LOSS: 0.6381010413169861 ACCURCY: 0.6609020716497125\n",
      "current epoch 9 ,  1.8 % completed\n",
      "LOSS: 0.6383658051490784 ACCURCY: 0.6198242052189296\n",
      "current epoch 10 ,  2.0 % completed\n",
      "LOSS: 0.6401045918464661 ACCURCY: 0.6388366351172049\n",
      "current epoch 11 ,  2.2 % completed\n",
      "LOSS: 0.6321401000022888 ACCURCY: 0.6512506218487394\n",
      "current epoch 12 ,  2.4 % completed\n",
      "LOSS: 0.6261422634124756 ACCURCY: 0.6656862061034938\n",
      "current epoch 13 ,  2.6 % completed\n",
      "LOSS: 0.6057866811752319 ACCURCY: 0.6514684475895622\n",
      "current epoch 14 ,  2.8 % completed\n",
      "LOSS: 0.6101737022399902 ACCURCY: 0.683486475011057\n",
      "current epoch 15 ,  3.0 % completed\n",
      "LOSS: 0.610763669013977 ACCURCY: 0.6821214011499336\n",
      "current epoch 16 ,  3.2 % completed\n",
      "LOSS: 0.6060506701469421 ACCURCY: 0.6812788642193718\n",
      "current epoch 17 ,  3.4 % completed\n",
      "LOSS: 0.6119329333305359 ACCURCY: 0.6752484882795222\n",
      "current epoch 18 ,  3.6 % completed\n",
      "LOSS: 0.5884674191474915 ACCURCY: 0.6803431862007961\n",
      "current epoch 19 ,  3.8 % completed\n",
      "LOSS: 0.6038591861724854 ACCURCY: 0.6798750252100841\n",
      "current epoch 20 ,  4.0 % completed\n",
      "LOSS: 0.6095557808876038 ACCURCY: 0.6713607430340557\n",
      "current epoch 21 ,  4.2 % completed\n",
      "LOSS: 0.6020127534866333 ACCURCY: 0.6856258575851393\n",
      "current epoch 22 ,  4.4 % completed\n",
      "LOSS: 0.6108304858207703 ACCURCY: 0.6730518036267139\n",
      "current epoch 23 ,  4.6 % completed\n",
      "LOSS: 0.6265459060668945 ACCURCY: 0.6834317098628924\n",
      "current epoch 24 ,  4.8 % completed\n",
      "LOSS: 0.5846071243286133 ACCURCY: 0.6855310924369747\n",
      "current epoch 25 ,  5.0 % completed\n",
      "LOSS: 0.6105564832687378 ACCURCY: 0.684948394515701\n",
      "current epoch 26 ,  5.2 % completed\n",
      "LOSS: 0.5965825915336609 ACCURCY: 0.6787137231313578\n",
      "current epoch 27 ,  5.4 % completed\n",
      "LOSS: 0.6108381152153015 ACCURCY: 0.6839757770897833\n",
      "current epoch 28 ,  5.6 % completed\n",
      "LOSS: 0.6144993901252747 ACCURCY: 0.6818455621406457\n",
      "current epoch 29 ,  5.8 % completed\n",
      "LOSS: 0.6055558919906616 ACCURCY: 0.6850342467934545\n",
      "current epoch 30 ,  6.0 % completed\n",
      "LOSS: 0.6013088822364807 ACCURCY: 0.6827019513489606\n",
      "current epoch 31 ,  6.2 % completed\n",
      "LOSS: 0.6012392640113831 ACCURCY: 0.6860738575851393\n",
      "current epoch 32 ,  6.4 % completed\n",
      "LOSS: 0.6076701879501343 ACCURCY: 0.6798220185758513\n",
      "current epoch 33 ,  6.6 % completed\n",
      "LOSS: 0.5971391201019287 ACCURCY: 0.6856856293675366\n",
      "current epoch 34 ,  6.8 % completed\n",
      "LOSS: 0.6136580109596252 ACCURCY: 0.6857379248120301\n",
      "current epoch 35 ,  7.0 % completed\n",
      "LOSS: 0.6170129776000977 ACCURCY: 0.677848944714728\n",
      "current epoch 36 ,  7.2 % completed\n",
      "LOSS: 0.6063107848167419 ACCURCY: 0.6793891729323307\n",
      "current epoch 37 ,  7.4 % completed\n",
      "LOSS: 0.6005603671073914 ACCURCY: 0.6840767837240159\n",
      "current epoch 38 ,  7.6 % completed\n",
      "LOSS: 0.6008831858634949 ACCURCY: 0.6851487164971253\n",
      "current epoch 39 ,  7.8 % completed\n",
      "LOSS: 0.6052919030189514 ACCURCY: 0.6856779513489606\n",
      "current epoch 40 ,  8.0 % completed\n",
      "LOSS: 0.5949167013168335 ACCURCY: 0.6849197770897831\n",
      "current epoch 41 ,  8.2 % completed\n",
      "LOSS: 0.5918289422988892 ACCURCY: 0.6761647164971252\n",
      "current epoch 42 ,  8.4 % completed\n",
      "LOSS: 0.5967316031455994 ACCURCY: 0.6863319380804953\n",
      "current epoch 43 ,  8.6 % completed\n",
      "LOSS: 0.6019092798233032 ACCURCY: 0.6859306360017692\n",
      "current epoch 44 ,  8.8 % completed\n",
      "LOSS: 0.6030582189559937 ACCURCY: 0.6837516426360017\n",
      "current epoch 45 ,  9.0 % completed\n",
      "LOSS: 0.5918750762939453 ACCURCY: 0.6864001662980982\n",
      "current epoch 46 ,  9.2 % completed\n",
      "LOSS: 0.6019967794418335 ACCURCY: 0.682584944714728\n",
      "current epoch 47 ,  9.4 % completed\n",
      "LOSS: 0.588040292263031 ACCURCY: 0.6826039380804955\n",
      "current epoch 48 ,  9.6 % completed\n",
      "LOSS: 0.6142987608909607 ACCURCY: 0.6858776293675365\n",
      "current epoch 49 ,  9.8 % completed\n",
      "LOSS: 0.6090367436408997 ACCURCY: 0.6863420185758514\n",
      "current epoch 50 ,  10.0 % completed\n",
      "LOSS: 0.5841522216796875 ACCURCY: 0.6821651729323308\n",
      "current epoch 51 ,  10.2 % completed\n",
      "LOSS: 0.5947573781013489 ACCURCY: 0.6834182467934542\n",
      "current epoch 52 ,  10.4 % completed\n",
      "LOSS: 0.5958049297332764 ACCURCY: 0.685054085802742\n",
      "current epoch 53 ,  10.6 % completed\n",
      "LOSS: 0.5964874029159546 ACCURCY: 0.6833718708536047\n",
      "current epoch 54 ,  10.8 % completed\n",
      "LOSS: 0.6065568923950195 ACCURCY: 0.6846086227333039\n",
      "current epoch 55 ,  11.0 % completed\n",
      "LOSS: 0.6025746464729309 ACCURCY: 0.6840687837240159\n",
      "current epoch 56 ,  11.2 % completed\n",
      "LOSS: 0.5981559157371521 ACCURCY: 0.6862987032286599\n",
      "current epoch 57 ,  11.4 % completed\n",
      "LOSS: 0.6055774092674255 ACCURCY: 0.6865210119416189\n",
      "current epoch 58 ,  11.6 % completed\n",
      "LOSS: 0.5996763110160828 ACCURCY: 0.6856527837240158\n",
      "current epoch 59 ,  11.8 % completed\n",
      "LOSS: 0.5952938795089722 ACCURCY: 0.6806076426360018\n",
      "current epoch 60 ,  12.0 % completed\n",
      "LOSS: 0.5906778573989868 ACCURCY: 0.6861050119416189\n",
      "current epoch 61 ,  12.2 % completed\n",
      "LOSS: 0.6117500066757202 ACCURCY: 0.6775124882795223\n",
      "current epoch 62 ,  12.4 % completed\n",
      "LOSS: 0.6121587157249451 ACCURCY: 0.6850598708536048\n",
      "current epoch 63 ,  12.6 % completed\n",
      "LOSS: 0.603445291519165 ACCURCY: 0.6863921662980982\n",
      "current epoch 64 ,  12.8 % completed\n",
      "LOSS: 0.605384349822998 ACCURCY: 0.6836030924369748\n",
      "current epoch 65 ,  13.0 % completed\n",
      "LOSS: 0.6164857745170593 ACCURCY: 0.6866363272888103\n",
      "current epoch 66 ,  13.2 % completed\n",
      "LOSS: 0.5995988845825195 ACCURCY: 0.6793675754091111\n",
      "current epoch 67 ,  13.4 % completed\n",
      "LOSS: 0.5978135466575623 ACCURCY: 0.6866233206545777\n",
      "current epoch 68 ,  13.6 % completed\n",
      "LOSS: 0.593161940574646 ACCURCY: 0.6798990252100842\n",
      "current epoch 69 ,  13.8 % completed\n",
      "LOSS: 0.5917801856994629 ACCURCY: 0.6857778575851392\n",
      "current epoch 70 ,  14.0 % completed\n",
      "LOSS: 0.6070505976676941 ACCURCY: 0.6852094011499338\n",
      "current epoch 71 ,  14.2 % completed\n",
      "LOSS: 0.6028865575790405 ACCURCY: 0.6837357098628926\n",
      "current epoch 72 ,  14.4 % completed\n",
      "LOSS: 0.5917552709579468 ACCURCY: 0.6860679380804956\n",
      "current epoch 73 ,  14.6 % completed\n",
      "LOSS: 0.6032266616821289 ACCURCY: 0.6840982467934542\n",
      "current epoch 74 ,  14.8 % completed\n",
      "LOSS: 0.6213070154190063 ACCURCY: 0.6778185687748784\n",
      "current epoch 75 ,  15.0 % completed\n",
      "LOSS: 0.612170934677124 ACCURCY: 0.6840118708536046\n",
      "current epoch 76 ,  15.2 % completed\n",
      "LOSS: 0.5973029136657715 ACCURCY: 0.6865896293675365\n",
      "current epoch 77 ,  15.4 % completed\n",
      "LOSS: 0.6024180054664612 ACCURCY: 0.6861774011499335\n",
      "current epoch 78 ,  15.6 % completed\n",
      "LOSS: 0.6132782697677612 ACCURCY: 0.6853917770897834\n",
      "current epoch 79 ,  15.8 % completed\n",
      "LOSS: 0.6191684007644653 ACCURCY: 0.6864797098628925\n",
      "current epoch 80 ,  16.0 % completed\n",
      "LOSS: 0.592551052570343 ACCURCY: 0.6846077098628924\n",
      "current epoch 81 ,  16.2 % completed\n",
      "LOSS: 0.5863357782363892 ACCURCY: 0.6850726227333038\n",
      "current epoch 82 ,  16.4 % completed\n",
      "LOSS: 0.5972684621810913 ACCURCY: 0.6820278708536045\n",
      "current epoch 83 ,  16.6 % completed\n",
      "LOSS: 0.5989473462104797 ACCURCY: 0.6827121662980983\n",
      "current epoch 84 ,  16.8 % completed\n",
      "LOSS: 0.6030828952789307 ACCURCY: 0.6862287837240159\n",
      "current epoch 85 ,  17.0 % completed\n",
      "LOSS: 0.6057531237602234 ACCURCY: 0.6857870924369748\n",
      "current epoch 86 ,  17.2 % completed\n",
      "LOSS: 0.6046537756919861 ACCURCY: 0.6853003945157009\n",
      "current epoch 87 ,  17.4 % completed\n",
      "LOSS: 0.6005019545555115 ACCURCY: 0.6845188642193719\n",
      "current epoch 88 ,  17.6 % completed\n",
      "LOSS: 0.6092209815979004 ACCURCY: 0.6862890119416188\n",
      "current epoch 89 ,  17.8 % completed\n",
      "LOSS: 0.598757803440094 ACCURCY: 0.6762231189739053\n",
      "current epoch 90 ,  18.0 % completed\n",
      "LOSS: 0.5931152105331421 ACCURCY: 0.6864418575851394\n",
      "current epoch 91 ,  18.2 % completed\n",
      "LOSS: 0.6007000207901001 ACCURCY: 0.6845774011499336\n",
      "current epoch 92 ,  18.4 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.5869458913803101 ACCURCY: 0.6858161662980978\n",
      "current epoch 93 ,  18.6 % completed\n",
      "LOSS: 0.6006065011024475 ACCURCY: 0.6826261795665635\n",
      "current epoch 94 ,  18.8 % completed\n",
      "LOSS: 0.6030330657958984 ACCURCY: 0.6854393206545778\n",
      "current epoch 95 ,  19.0 % completed\n",
      "LOSS: 0.5995429754257202 ACCURCY: 0.686270475011057\n",
      "current epoch 96 ,  19.2 % completed\n",
      "LOSS: 0.6075077652931213 ACCURCY: 0.6820417903582485\n",
      "current epoch 97 ,  19.4 % completed\n",
      "LOSS: 0.5984312295913696 ACCURCY: 0.6818073206545777\n",
      "current epoch 98 ,  19.6 % completed\n",
      "LOSS: 0.6189706921577454 ACCURCY: 0.6842148642193719\n",
      "current epoch 99 ,  19.8 % completed\n",
      "LOSS: 0.5864501595497131 ACCURCY: 0.6841416293675365\n",
      "current epoch 100 ,  20.0 % completed\n",
      "LOSS: 0.5896294116973877 ACCURCY: 0.6854898575851394\n",
      "current epoch 101 ,  20.2 % completed\n",
      "LOSS: 0.6081750392913818 ACCURCY: 0.6851534011499338\n",
      "current epoch 102 ,  20.4 % completed\n",
      "LOSS: 0.5884372591972351 ACCURCY: 0.6808779513489606\n",
      "current epoch 103 ,  20.6 % completed\n",
      "LOSS: 0.6052948832511902 ACCURCY: 0.6860090791685097\n",
      "current epoch 104 ,  20.8 % completed\n",
      "LOSS: 0.6092028617858887 ACCURCY: 0.6853158708536046\n",
      "current epoch 105 ,  21.0 % completed\n",
      "LOSS: 0.6020543575286865 ACCURCY: 0.6830030924369747\n",
      "current epoch 106 ,  21.2 % completed\n",
      "LOSS: 0.608226478099823 ACCURCY: 0.6846153206545776\n",
      "current epoch 107 ,  21.4 % completed\n",
      "LOSS: 0.5984388589859009 ACCURCY: 0.6855537903582484\n",
      "current epoch 108 ,  21.6 % completed\n",
      "LOSS: 0.610610842704773 ACCURCY: 0.6812497903582485\n",
      "current epoch 109 ,  21.8 % completed\n",
      "LOSS: 0.6122137904167175 ACCURCY: 0.6852309314462629\n",
      "current epoch 110 ,  22.0 % completed\n",
      "LOSS: 0.5948412418365479 ACCURCY: 0.6853046227333038\n",
      "current epoch 111 ,  22.2 % completed\n",
      "LOSS: 0.6050925254821777 ACCURCY: 0.6831399380804954\n",
      "current epoch 112 ,  22.4 % completed\n",
      "LOSS: 0.6101037263870239 ACCURCY: 0.6833138575851393\n",
      "current epoch 113 ,  22.6 % completed\n",
      "LOSS: 0.604621946811676 ACCURCY: 0.6846043272888103\n",
      "current epoch 114 ,  22.8 % completed\n",
      "LOSS: 0.6049224138259888 ACCURCY: 0.6842485555064131\n",
      "current epoch 115 ,  23.0 % completed\n",
      "LOSS: 0.6058909893035889 ACCURCY: 0.6857230252100841\n",
      "current epoch 116 ,  23.2 % completed\n",
      "LOSS: 0.5947605967521667 ACCURCY: 0.6857011729323308\n",
      "current epoch 117 ,  23.4 % completed\n",
      "LOSS: 0.6049352288246155 ACCURCY: 0.686342475011057\n",
      "current epoch 118 ,  23.6 % completed\n",
      "LOSS: 0.6072745323181152 ACCURCY: 0.6861095621406456\n",
      "current epoch 119 ,  23.8 % completed\n",
      "LOSS: 0.5839200019836426 ACCURCY: 0.6856750924369749\n",
      "current epoch 120 ,  24.0 % completed\n",
      "LOSS: 0.5975630283355713 ACCURCY: 0.6855391596638657\n",
      "current epoch 121 ,  24.2 % completed\n",
      "LOSS: 0.6112786531448364 ACCURCY: 0.6835214011499338\n",
      "current epoch 122 ,  24.4 % completed\n",
      "LOSS: 0.584195613861084 ACCURCY: 0.6865934683768247\n",
      "current epoch 123 ,  24.6 % completed\n",
      "LOSS: 0.5889396667480469 ACCURCY: 0.6852754816452896\n",
      "current epoch 124 ,  24.8 % completed\n",
      "LOSS: 0.5928470492362976 ACCURCY: 0.6861466360017691\n",
      "current epoch 125 ,  25.0 % completed\n",
      "LOSS: 0.5939125418663025 ACCURCY: 0.6829567837240158\n",
      "current epoch 126 ,  25.2 % completed\n",
      "LOSS: 0.6131865382194519 ACCURCY: 0.6857593206545777\n",
      "current epoch 127 ,  25.4 % completed\n",
      "LOSS: 0.5915368795394897 ACCURCY: 0.6837091729323308\n",
      "current epoch 128 ,  25.6 % completed\n",
      "LOSS: 0.6009533405303955 ACCURCY: 0.6860160990712074\n",
      "current epoch 129 ,  25.8 % completed\n",
      "LOSS: 0.5924692749977112 ACCURCY: 0.6860695621406456\n",
      "current epoch 130 ,  26.0 % completed\n",
      "LOSS: 0.5828067660331726 ACCURCY: 0.6853757770897831\n",
      "current epoch 131 ,  26.2 % completed\n",
      "LOSS: 0.610812783241272 ACCURCY: 0.6863845555064132\n",
      "current epoch 132 ,  26.4 % completed\n",
      "LOSS: 0.5935479998588562 ACCURCY: 0.685032944714728\n",
      "current epoch 133 ,  26.6 % completed\n",
      "LOSS: 0.6200566291809082 ACCURCY: 0.6825576293675364\n",
      "current epoch 134 ,  26.8 % completed\n",
      "LOSS: 0.5931894183158875 ACCURCY: 0.6875937903582485\n",
      "current epoch 135 ,  27.0 % completed\n",
      "LOSS: 0.6002320051193237 ACCURCY: 0.6871525555064131\n",
      "current epoch 136 ,  27.2 % completed\n",
      "LOSS: 0.6065415740013123 ACCURCY: 0.6864674816452896\n",
      "current epoch 137 ,  27.4 % completed\n",
      "LOSS: 0.5924624800682068 ACCURCY: 0.6827029314462628\n",
      "current epoch 138 ,  27.6 % completed\n",
      "LOSS: 0.6126024723052979 ACCURCY: 0.6867011729323306\n",
      "current epoch 139 ,  27.8 % completed\n",
      "LOSS: 0.5974075794219971 ACCURCY: 0.685550085802742\n",
      "current epoch 140 ,  28.0 % completed\n",
      "LOSS: 0.6023980975151062 ACCURCY: 0.6855879380804955\n",
      "current epoch 141 ,  28.2 % completed\n",
      "LOSS: 0.5923300981521606 ACCURCY: 0.6868949314462628\n",
      "current epoch 142 ,  28.4 % completed\n",
      "LOSS: 0.5989598035812378 ACCURCY: 0.6817496293675366\n",
      "current epoch 143 ,  28.6 % completed\n",
      "LOSS: 0.6038912534713745 ACCURCY: 0.6841297903582486\n",
      "current epoch 144 ,  28.8 % completed\n",
      "LOSS: 0.5994252562522888 ACCURCY: 0.6863109314462628\n",
      "current epoch 145 ,  29.0 % completed\n",
      "LOSS: 0.6011443138122559 ACCURCY: 0.6794126492702344\n",
      "current epoch 146 ,  29.2 % completed\n",
      "LOSS: 0.6072835326194763 ACCURCY: 0.6863925555064132\n",
      "current epoch 147 ,  29.4 % completed\n",
      "LOSS: 0.5862909555435181 ACCURCY: 0.6855921662980982\n",
      "current epoch 148 ,  29.6 % completed\n",
      "LOSS: 0.6058186888694763 ACCURCY: 0.6868270252100842\n",
      "current epoch 149 ,  29.8 % completed\n",
      "LOSS: 0.5928871631622314 ACCURCY: 0.6813301795665635\n",
      "current epoch 150 ,  30.0 % completed\n",
      "LOSS: 0.5912766456604004 ACCURCY: 0.6826864750110571\n",
      "current epoch 151 ,  30.2 % completed\n",
      "LOSS: 0.5922086834907532 ACCURCY: 0.6855012401592215\n",
      "current epoch 152 ,  30.4 % completed\n",
      "LOSS: 0.5968278646469116 ACCURCY: 0.6859588642193719\n",
      "current epoch 153 ,  30.6 % completed\n",
      "LOSS: 0.6049432754516602 ACCURCY: 0.6857314816452896\n",
      "current epoch 154 ,  30.8 % completed\n",
      "LOSS: 0.6087651252746582 ACCURCY: 0.681168944714728\n",
      "current epoch 155 ,  31.0 % completed\n",
      "LOSS: 0.5972747802734375 ACCURCY: 0.683342475011057\n",
      "current epoch 156 ,  31.2 % completed\n",
      "LOSS: 0.5945497155189514 ACCURCY: 0.6858683272888103\n",
      "current epoch 157 ,  31.4 % completed\n",
      "LOSS: 0.6024900674819946 ACCURCY: 0.6821387032286599\n",
      "current epoch 158 ,  31.6 % completed\n",
      "LOSS: 0.6005799174308777 ACCURCY: 0.6852696293675367\n",
      "current epoch 159 ,  31.8 % completed\n",
      "LOSS: 0.6078752279281616 ACCURCY: 0.6846291729323307\n",
      "current epoch 160 ,  32.0 % completed\n",
      "LOSS: 0.6024907827377319 ACCURCY: 0.6835563945157009\n",
      "current epoch 161 ,  32.2 % completed\n",
      "LOSS: 0.6025494933128357 ACCURCY: 0.6845950924369747\n",
      "current epoch 162 ,  32.4 % completed\n",
      "LOSS: 0.604209840297699 ACCURCY: 0.6837297903582485\n",
      "current epoch 163 ,  32.6 % completed\n",
      "LOSS: 0.5987460613250732 ACCURCY: 0.686682314020345\n",
      "current epoch 164 ,  32.8 % completed\n",
      "LOSS: 0.5948007702827454 ACCURCY: 0.6794884210526316\n",
      "current epoch 165 ,  33.0 % completed\n",
      "LOSS: 0.5957751870155334 ACCURCY: 0.6865559380804954\n",
      "current epoch 166 ,  33.2 % completed\n",
      "LOSS: 0.596610426902771 ACCURCY: 0.6862940858027422\n",
      "current epoch 167 ,  33.4 % completed\n",
      "LOSS: 0.5921792984008789 ACCURCY: 0.6858616293675365\n",
      "current epoch 168 ,  33.6 % completed\n",
      "LOSS: 0.5956093072891235 ACCURCY: 0.6869748642193718\n",
      "current epoch 169 ,  33.8 % completed\n",
      "LOSS: 0.5969196557998657 ACCURCY: 0.6862641662980983\n",
      "current epoch 170 ,  34.0 % completed\n",
      "LOSS: 0.5954606533050537 ACCURCY: 0.6850304077841664\n",
      "current epoch 171 ,  34.2 % completed\n",
      "LOSS: 0.5955135822296143 ACCURCY: 0.6837024077841665\n",
      "current epoch 172 ,  34.4 % completed\n",
      "LOSS: 0.6021772623062134 ACCURCY: 0.6860650119416186\n",
      "current epoch 173 ,  34.6 % completed\n",
      "LOSS: 0.5854994654655457 ACCURCY: 0.6860872534276866\n",
      "current epoch 174 ,  34.8 % completed\n",
      "LOSS: 0.6026972532272339 ACCURCY: 0.6835870924369748\n",
      "current epoch 175 ,  35.0 % completed\n",
      "LOSS: 0.6006942987442017 ACCURCY: 0.6865007837240159\n",
      "current epoch 176 ,  35.2 % completed\n",
      "LOSS: 0.6175349354743958 ACCURCY: 0.6859074816452897\n",
      "current epoch 177 ,  35.4 % completed\n",
      "LOSS: 0.6029710173606873 ACCURCY: 0.6831824750110569\n",
      "current epoch 178 ,  35.6 % completed\n",
      "LOSS: 0.6098125576972961 ACCURCY: 0.6821558708536046\n",
      "current epoch 179 ,  35.8 % completed\n",
      "LOSS: 0.6038474440574646 ACCURCY: 0.6856577903582485\n",
      "current epoch 180 ,  36.0 % completed\n",
      "LOSS: 0.5936846733093262 ACCURCY: 0.6862599380804952\n",
      "current epoch 181 ,  36.2 % completed\n",
      "LOSS: 0.6014297604560852 ACCURCY: 0.6786126492702345\n",
      "current epoch 182 ,  36.4 % completed\n",
      "LOSS: 0.6011409759521484 ACCURCY: 0.6846283272888103\n",
      "current epoch 183 ,  36.6 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6138305068016052 ACCURCY: 0.6809545687748781\n",
      "current epoch 184 ,  36.8 % completed\n",
      "LOSS: 0.5963548421859741 ACCURCY: 0.6848948642193718\n",
      "current epoch 185 ,  37.0 % completed\n",
      "LOSS: 0.5997931361198425 ACCURCY: 0.6861576293675369\n",
      "current epoch 186 ,  37.2 % completed\n",
      "LOSS: 0.5926401019096375 ACCURCY: 0.6856418575851393\n",
      "current epoch 187 ,  37.4 % completed\n",
      "LOSS: 0.6005930304527283 ACCURCY: 0.6864077098628926\n",
      "current epoch 188 ,  37.6 % completed\n",
      "LOSS: 0.6115558743476868 ACCURCY: 0.6847277098628927\n",
      "current epoch 189 ,  37.8 % completed\n",
      "LOSS: 0.5967686772346497 ACCURCY: 0.6786270252100841\n",
      "current epoch 190 ,  38.0 % completed\n",
      "LOSS: 0.6000251173973083 ACCURCY: 0.6842000990712074\n",
      "current epoch 191 ,  38.2 % completed\n",
      "LOSS: 0.605358898639679 ACCURCY: 0.686972394515701\n",
      "current epoch 192 ,  38.4 % completed\n",
      "LOSS: 0.6141431927680969 ACCURCY: 0.6857593206545777\n",
      "current epoch 193 ,  38.6 % completed\n",
      "LOSS: 0.5935669541358948 ACCURCY: 0.6847685555064131\n",
      "current epoch 194 ,  38.8 % completed\n",
      "LOSS: 0.5956376791000366 ACCURCY: 0.6832047837240159\n",
      "current epoch 195 ,  39.0 % completed\n",
      "LOSS: 0.6116741895675659 ACCURCY: 0.6854805555064131\n",
      "current epoch 196 ,  39.2 % completed\n",
      "LOSS: 0.5843054056167603 ACCURCY: 0.6864881662980983\n",
      "current epoch 197 ,  39.4 % completed\n",
      "LOSS: 0.595967173576355 ACCURCY: 0.68371470322866\n",
      "current epoch 198 ,  39.6 % completed\n",
      "LOSS: 0.6181565523147583 ACCURCY: 0.686112166298098\n",
      "current epoch 199 ,  39.8 % completed\n",
      "LOSS: 0.6029292941093445 ACCURCY: 0.6802607164971252\n",
      "current epoch 200 ,  40.0 % completed\n",
      "LOSS: 0.6159989237785339 ACCURCY: 0.6858439380804954\n",
      "current epoch 201 ,  40.2 % completed\n",
      "LOSS: 0.5999031066894531 ACCURCY: 0.6843563945157011\n",
      "current epoch 202 ,  40.4 % completed\n",
      "LOSS: 0.6096728444099426 ACCURCY: 0.6829841662980982\n",
      "current epoch 203 ,  40.6 % completed\n",
      "LOSS: 0.5931279063224792 ACCURCY: 0.6816947969924813\n",
      "current epoch 204 ,  40.8 % completed\n",
      "LOSS: 0.603767454624176 ACCURCY: 0.6856789314462628\n",
      "current epoch 205 ,  41.0 % completed\n",
      "LOSS: 0.5901426076889038 ACCURCY: 0.6830097903582485\n",
      "current epoch 206 ,  41.2 % completed\n",
      "LOSS: 0.6009547114372253 ACCURCY: 0.6829285555064131\n",
      "current epoch 207 ,  41.4 % completed\n",
      "LOSS: 0.5856892466545105 ACCURCY: 0.6856216293675363\n",
      "current epoch 208 ,  41.6 % completed\n",
      "LOSS: 0.5871103405952454 ACCURCY: 0.6861332401592216\n",
      "current epoch 209 ,  41.8 % completed\n",
      "LOSS: 0.5948194861412048 ACCURCY: 0.6863710924369747\n",
      "current epoch 210 ,  42.0 % completed\n",
      "LOSS: 0.598538875579834 ACCURCY: 0.6854502467934541\n",
      "current epoch 211 ,  42.2 % completed\n",
      "LOSS: 0.6176388263702393 ACCURCY: 0.6853205555064131\n",
      "current epoch 212 ,  42.4 % completed\n",
      "LOSS: 0.6052466630935669 ACCURCY: 0.6827491729323308\n",
      "current epoch 213 ,  42.6 % completed\n",
      "LOSS: 0.5967673659324646 ACCURCY: 0.6799407164971251\n",
      "current epoch 214 ,  42.8 % completed\n",
      "LOSS: 0.5971570611000061 ACCURCY: 0.6859627032286597\n",
      "current epoch 215 ,  43.0 % completed\n",
      "LOSS: 0.5895241498947144 ACCURCY: 0.6857719380804954\n",
      "current epoch 216 ,  43.2 % completed\n",
      "LOSS: 0.6012383103370667 ACCURCY: 0.6835592534276868\n",
      "current epoch 217 ,  43.4 % completed\n",
      "LOSS: 0.5820208191871643 ACCURCY: 0.6848208509509068\n",
      "current epoch 218 ,  43.6 % completed\n",
      "LOSS: 0.5939462184906006 ACCURCY: 0.684316394515701\n",
      "current epoch 219 ,  43.8 % completed\n",
      "LOSS: 0.6008794903755188 ACCURCY: 0.6855681662980981\n",
      "current epoch 220 ,  44.0 % completed\n",
      "LOSS: 0.6071720123291016 ACCURCY: 0.6853020185758514\n",
      "current epoch 221 ,  44.2 % completed\n",
      "LOSS: 0.6075398325920105 ACCURCY: 0.6861589314462628\n",
      "current epoch 222 ,  44.4 % completed\n",
      "LOSS: 0.6003196239471436 ACCURCY: 0.6838480990712074\n",
      "current epoch 223 ,  44.6 % completed\n",
      "LOSS: 0.6080208420753479 ACCURCY: 0.6842422467934542\n",
      "current epoch 224 ,  44.8 % completed\n",
      "LOSS: 0.5862594246864319 ACCURCY: 0.6870313206545776\n",
      "current epoch 225 ,  45.0 % completed\n",
      "LOSS: 0.5982345342636108 ACCURCY: 0.6864190924369747\n",
      "current epoch 226 ,  45.2 % completed\n",
      "LOSS: 0.6092678904533386 ACCURCY: 0.686222864219372\n",
      "current epoch 227 ,  45.4 % completed\n",
      "LOSS: 0.6074231863021851 ACCURCY: 0.6859904750110571\n",
      "current epoch 228 ,  45.6 % completed\n",
      "LOSS: 0.6140830516815186 ACCURCY: 0.6862691729323308\n",
      "current epoch 229 ,  45.8 % completed\n",
      "LOSS: 0.5906111001968384 ACCURCY: 0.6857593206545777\n",
      "current epoch 230 ,  46.0 % completed\n",
      "LOSS: 0.6022343039512634 ACCURCY: 0.6864574683768245\n",
      "current epoch 231 ,  46.2 % completed\n",
      "LOSS: 0.5993877053260803 ACCURCY: 0.6861597098628924\n",
      "current epoch 232 ,  46.4 % completed\n",
      "LOSS: 0.6123351454734802 ACCURCY: 0.6850034816452896\n",
      "current epoch 233 ,  46.6 % completed\n",
      "LOSS: 0.6155577301979065 ACCURCY: 0.6863845555064131\n",
      "current epoch 234 ,  46.8 % completed\n",
      "LOSS: 0.5956427454948425 ACCURCY: 0.6863896965944272\n",
      "current epoch 235 ,  47.0 % completed\n",
      "LOSS: 0.5992826223373413 ACCURCY: 0.6839172401592216\n",
      "current epoch 236 ,  47.2 % completed\n",
      "LOSS: 0.5820010900497437 ACCURCY: 0.6838157098628923\n",
      "current epoch 237 ,  47.4 % completed\n",
      "LOSS: 0.6079172492027283 ACCURCY: 0.686084394515701\n",
      "current epoch 238 ,  47.6 % completed\n",
      "LOSS: 0.587138831615448 ACCURCY: 0.6823024077841663\n",
      "current epoch 239 ,  47.8 % completed\n",
      "LOSS: 0.5897722840309143 ACCURCY: 0.6861450119416187\n",
      "current epoch 240 ,  48.0 % completed\n",
      "LOSS: 0.587944507598877 ACCURCY: 0.685512166298098\n",
      "current epoch 241 ,  48.2 % completed\n",
      "LOSS: 0.5964205861091614 ACCURCY: 0.6860726227333039\n",
      "current epoch 242 ,  48.4 % completed\n",
      "LOSS: 0.6033594608306885 ACCURCY: 0.6860080990712073\n",
      "current epoch 243 ,  48.6 % completed\n",
      "LOSS: 0.5961400866508484 ACCURCY: 0.6859323945157009\n",
      "current epoch 244 ,  48.8 % completed\n",
      "LOSS: 0.5995581150054932 ACCURCY: 0.6865264750110569\n",
      "current epoch 245 ,  49.0 % completed\n",
      "LOSS: 0.5922814607620239 ACCURCY: 0.6859016965944272\n",
      "current epoch 246 ,  49.2 % completed\n",
      "LOSS: 0.6113099455833435 ACCURCY: 0.6840014011499336\n",
      "current epoch 247 ,  49.4 % completed\n",
      "LOSS: 0.5916741490364075 ACCURCY: 0.6805339513489607\n",
      "current epoch 248 ,  49.6 % completed\n",
      "LOSS: 0.6104773879051208 ACCURCY: 0.6855331057054399\n",
      "current epoch 249 ,  49.8 % completed\n",
      "LOSS: 0.6014662384986877 ACCURCY: 0.6853718708536046\n",
      "current epoch 250 ,  50.0 % completed\n",
      "LOSS: 0.6056731343269348 ACCURCY: 0.6842670924369747\n",
      "current epoch 251 ,  50.2 % completed\n",
      "LOSS: 0.5943877100944519 ACCURCY: 0.6858077098628924\n",
      "current epoch 252 ,  50.4 % completed\n",
      "LOSS: 0.6082516312599182 ACCURCY: 0.6840960990712074\n",
      "current epoch 253 ,  50.6 % completed\n",
      "LOSS: 0.5942131876945496 ACCURCY: 0.6852502467934544\n",
      "current epoch 254 ,  50.8 % completed\n",
      "LOSS: 0.5801002383232117 ACCURCY: 0.6860881662980983\n",
      "current epoch 255 ,  51.0 % completed\n",
      "LOSS: 0.6094118356704712 ACCURCY: 0.6838994816452897\n",
      "current epoch 256 ,  51.2 % completed\n",
      "LOSS: 0.5993669629096985 ACCURCY: 0.6828359380804955\n",
      "current epoch 257 ,  51.4 % completed\n",
      "LOSS: 0.6171166896820068 ACCURCY: 0.6840582467934542\n",
      "current epoch 258 ,  51.6 % completed\n",
      "LOSS: 0.605125904083252 ACCURCY: 0.6862022467934543\n",
      "current epoch 259 ,  51.8 % completed\n",
      "LOSS: 0.5964160561561584 ACCURCY: 0.6853138575851393\n",
      "current epoch 260 ,  52.0 % completed\n",
      "LOSS: 0.6059273481369019 ACCURCY: 0.6855403272888103\n",
      "current epoch 261 ,  52.2 % completed\n",
      "LOSS: 0.6019843220710754 ACCURCY: 0.6860990924369749\n",
      "current epoch 262 ,  52.4 % completed\n",
      "LOSS: 0.6010912656784058 ACCURCY: 0.685066314020345\n",
      "current epoch 263 ,  52.6 % completed\n",
      "LOSS: 0.5855090618133545 ACCURCY: 0.6849887837240157\n",
      "current epoch 264 ,  52.8 % completed\n",
      "LOSS: 0.5989935994148254 ACCURCY: 0.6868144750110571\n",
      "current epoch 265 ,  53.0 % completed\n",
      "LOSS: 0.594523549079895 ACCURCY: 0.684446864219372\n",
      "current epoch 266 ,  53.2 % completed\n",
      "LOSS: 0.6049177646636963 ACCURCY: 0.6827525555064132\n",
      "current epoch 267 ,  53.4 % completed\n",
      "LOSS: 0.5947281718254089 ACCURCY: 0.684160944714728\n",
      "current epoch 268 ,  53.6 % completed\n",
      "LOSS: 0.6047345995903015 ACCURCY: 0.6856035488721807\n",
      "current epoch 269 ,  53.8 % completed\n",
      "LOSS: 0.5916140079498291 ACCURCY: 0.6840261795665634\n",
      "current epoch 270 ,  54.0 % completed\n",
      "LOSS: 0.6078376770019531 ACCURCY: 0.6858708642193717\n",
      "current epoch 271 ,  54.2 % completed\n",
      "LOSS: 0.598099946975708 ACCURCY: 0.6867251729323307\n",
      "current epoch 272 ,  54.4 % completed\n",
      "LOSS: 0.5987184643745422 ACCURCY: 0.6861652401592216\n",
      "current epoch 273 ,  54.6 % completed\n",
      "LOSS: 0.5937325358390808 ACCURCY: 0.6849462467934542\n",
      "current epoch 274 ,  54.8 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6072683334350586 ACCURCY: 0.686092005307386\n",
      "current epoch 275 ,  55.0 % completed\n",
      "LOSS: 0.6006143093109131 ACCURCY: 0.6817925555064133\n",
      "current epoch 276 ,  55.2 % completed\n",
      "LOSS: 0.592300295829773 ACCURCY: 0.6865450119416188\n",
      "current epoch 277 ,  55.4 % completed\n",
      "LOSS: 0.600728452205658 ACCURCY: 0.6803061795665636\n",
      "current epoch 278 ,  55.6 % completed\n",
      "LOSS: 0.5975968837738037 ACCURCY: 0.6852014011499337\n",
      "current epoch 279 ,  55.8 % completed\n",
      "LOSS: 0.5859712958335876 ACCURCY: 0.6857441662980983\n",
      "current epoch 280 ,  56.0 % completed\n",
      "LOSS: 0.5803231596946716 ACCURCY: 0.6862840053073862\n",
      "current epoch 281 ,  56.2 % completed\n",
      "LOSS: 0.5984371900558472 ACCURCY: 0.6846503140203449\n",
      "current epoch 282 ,  56.4 % completed\n",
      "LOSS: 0.5967857837677002 ACCURCY: 0.6866608509509067\n",
      "current epoch 283 ,  56.6 % completed\n",
      "LOSS: 0.6015993356704712 ACCURCY: 0.6846090119416188\n",
      "current epoch 284 ,  56.8 % completed\n",
      "LOSS: 0.6017032861709595 ACCURCY: 0.6856183140203451\n",
      "current epoch 285 ,  57.0 % completed\n",
      "LOSS: 0.583544909954071 ACCURCY: 0.6834713206545777\n",
      "current epoch 286 ,  57.2 % completed\n",
      "LOSS: 0.6099664568901062 ACCURCY: 0.6841411729323308\n",
      "current epoch 287 ,  57.4 % completed\n",
      "LOSS: 0.5855278372764587 ACCURCY: 0.6818126492702342\n",
      "current epoch 288 ,  57.6 % completed\n",
      "LOSS: 0.5966194272041321 ACCURCY: 0.685142864219372\n",
      "current epoch 289 ,  57.8 % completed\n",
      "LOSS: 0.5875911712646484 ACCURCY: 0.6853640053073862\n",
      "current epoch 290 ,  58.0 % completed\n",
      "LOSS: 0.611522376537323 ACCURCY: 0.6859323272888104\n",
      "current epoch 291 ,  58.2 % completed\n",
      "LOSS: 0.5977655649185181 ACCURCY: 0.6827243272888103\n",
      "current epoch 292 ,  58.4 % completed\n",
      "LOSS: 0.6114594340324402 ACCURCY: 0.6853627032286598\n",
      "current epoch 293 ,  58.6 % completed\n",
      "LOSS: 0.6021257638931274 ACCURCY: 0.686358475011057\n",
      "current epoch 294 ,  58.8 % completed\n",
      "LOSS: 0.5908950567245483 ACCURCY: 0.6854822467934544\n",
      "current epoch 295 ,  59.0 % completed\n",
      "LOSS: 0.6095073819160461 ACCURCY: 0.6834317098628925\n",
      "current epoch 296 ,  59.2 % completed\n",
      "LOSS: 0.6124182343482971 ACCURCY: 0.6856153206545779\n",
      "current epoch 297 ,  59.4 % completed\n",
      "LOSS: 0.6025041937828064 ACCURCY: 0.6843348642193717\n",
      "current epoch 298 ,  59.6 % completed\n",
      "LOSS: 0.5998581647872925 ACCURCY: 0.682598475011057\n",
      "current epoch 299 ,  59.8 % completed\n",
      "LOSS: 0.5989077687263489 ACCURCY: 0.685820394515701\n",
      "current epoch 300 ,  60.0 % completed\n",
      "LOSS: 0.5919362306594849 ACCURCY: 0.6855660858027421\n",
      "current epoch 301 ,  60.2 % completed\n",
      "LOSS: 0.594562292098999 ACCURCY: 0.6864149314462626\n",
      "current epoch 302 ,  60.4 % completed\n",
      "LOSS: 0.5996995568275452 ACCURCY: 0.6858999380804954\n",
      "current epoch 303 ,  60.6 % completed\n",
      "LOSS: 0.6111243367195129 ACCURCY: 0.6859740858027421\n",
      "current epoch 304 ,  60.8 % completed\n",
      "LOSS: 0.5996336340904236 ACCURCY: 0.6852960990712075\n",
      "current epoch 305 ,  61.0 % completed\n",
      "LOSS: 0.599785566329956 ACCURCY: 0.6862473206545778\n",
      "current epoch 306 ,  61.2 % completed\n",
      "LOSS: 0.6015545129776001 ACCURCY: 0.6863134011499334\n",
      "current epoch 307 ,  61.4 % completed\n",
      "LOSS: 0.6079742908477783 ACCURCY: 0.6846440053073861\n",
      "current epoch 308 ,  61.6 % completed\n",
      "LOSS: 0.5921685099601746 ACCURCY: 0.6828661795665633\n",
      "current epoch 309 ,  61.8 % completed\n",
      "LOSS: 0.6036847233772278 ACCURCY: 0.6842547969924815\n",
      "current epoch 310 ,  62.0 % completed\n",
      "LOSS: 0.6001975536346436 ACCURCY: 0.6858667032286598\n",
      "current epoch 311 ,  62.2 % completed\n",
      "LOSS: 0.6026987433433533 ACCURCY: 0.6843277098628926\n",
      "current epoch 312 ,  62.4 % completed\n",
      "LOSS: 0.601899266242981 ACCURCY: 0.6875227704555508\n",
      "current epoch 313 ,  62.6 % completed\n",
      "LOSS: 0.6125048398971558 ACCURCY: 0.6862772401592215\n",
      "current epoch 314 ,  62.8 % completed\n",
      "LOSS: 0.6002687811851501 ACCURCY: 0.6853870924369747\n",
      "current epoch 315 ,  63.0 % completed\n",
      "LOSS: 0.6081496477127075 ACCURCY: 0.6844000990712076\n",
      "current epoch 316 ,  63.2 % completed\n",
      "LOSS: 0.6127347946166992 ACCURCY: 0.6820144750110569\n",
      "current epoch 317 ,  63.4 % completed\n",
      "LOSS: 0.5868259072303772 ACCURCY: 0.6851807837240158\n",
      "current epoch 318 ,  63.6 % completed\n",
      "LOSS: 0.615251898765564 ACCURCY: 0.6828363272888103\n",
      "current epoch 319 ,  63.8 % completed\n",
      "LOSS: 0.6065828800201416 ACCURCY: 0.6849677098628925\n",
      "current epoch 320 ,  64.0 % completed\n",
      "LOSS: 0.5975463390350342 ACCURCY: 0.6872856965944272\n",
      "current epoch 321 ,  64.2 % completed\n",
      "LOSS: 0.5978037714958191 ACCURCY: 0.6856890119416187\n",
      "current epoch 322 ,  64.4 % completed\n",
      "LOSS: 0.6035440564155579 ACCURCY: 0.6850215621406457\n",
      "current epoch 323 ,  64.6 % completed\n",
      "LOSS: 0.5973484516143799 ACCURCY: 0.6853311596638655\n",
      "current epoch 324 ,  64.8 % completed\n",
      "LOSS: 0.585854709148407 ACCURCY: 0.6843445555064132\n",
      "current epoch 325 ,  65.0 % completed\n",
      "LOSS: 0.5997467041015625 ACCURCY: 0.6867480053073859\n",
      "current epoch 326 ,  65.2 % completed\n",
      "LOSS: 0.6168217062950134 ACCURCY: 0.6858140858027422\n",
      "current epoch 327 ,  65.4 % completed\n",
      "LOSS: 0.5954623222351074 ACCURCY: 0.685153333923043\n",
      "current epoch 328 ,  65.6 % completed\n",
      "LOSS: 0.5949714779853821 ACCURCY: 0.6820232534276869\n",
      "current epoch 329 ,  65.8 % completed\n",
      "LOSS: 0.5882938504219055 ACCURCY: 0.684849011941619\n",
      "current epoch 330 ,  66.0 % completed\n",
      "LOSS: 0.6044067740440369 ACCURCY: 0.6851433206545775\n",
      "current epoch 331 ,  66.2 % completed\n",
      "LOSS: 0.6012153029441833 ACCURCY: 0.6858696293675365\n",
      "current epoch 332 ,  66.4 % completed\n",
      "LOSS: 0.5864822268486023 ACCURCY: 0.6814503140203447\n",
      "current epoch 333 ,  66.6 % completed\n",
      "LOSS: 0.5780889987945557 ACCURCY: 0.6858341795665635\n",
      "current epoch 334 ,  66.8 % completed\n",
      "LOSS: 0.5906559228897095 ACCURCY: 0.6838097903582484\n",
      "current epoch 335 ,  67.0 % completed\n",
      "LOSS: 0.600999653339386 ACCURCY: 0.686617011941619\n",
      "current epoch 336 ,  67.2 % completed\n",
      "LOSS: 0.5958148837089539 ACCURCY: 0.6846073206545775\n",
      "current epoch 337 ,  67.4 % completed\n",
      "LOSS: 0.5724619030952454 ACCURCY: 0.686102085802742\n",
      "current epoch 338 ,  67.6 % completed\n",
      "LOSS: 0.6065361499786377 ACCURCY: 0.6857900185758514\n",
      "current epoch 339 ,  67.8 % completed\n",
      "LOSS: 0.6076496243476868 ACCURCY: 0.6838814011499338\n",
      "current epoch 340 ,  68.0 % completed\n",
      "LOSS: 0.5952566862106323 ACCURCY: 0.6858017903582485\n",
      "current epoch 341 ,  68.2 % completed\n",
      "LOSS: 0.6024276614189148 ACCURCY: 0.6849760990712074\n",
      "current epoch 342 ,  68.4 % completed\n",
      "LOSS: 0.6048229932785034 ACCURCY: 0.6843150924369747\n",
      "current epoch 343 ,  68.6 % completed\n",
      "LOSS: 0.6072798371315002 ACCURCY: 0.6860498575851394\n",
      "current epoch 344 ,  68.8 % completed\n",
      "LOSS: 0.5818280577659607 ACCURCY: 0.6862814011499335\n",
      "current epoch 345 ,  69.0 % completed\n",
      "LOSS: 0.605209231376648 ACCURCY: 0.6859297903582484\n",
      "current epoch 346 ,  69.2 % completed\n",
      "LOSS: 0.5975286960601807 ACCURCY: 0.6839470924369748\n",
      "current epoch 347 ,  69.4 % completed\n",
      "LOSS: 0.5991418361663818 ACCURCY: 0.68429310570544\n",
      "current epoch 348 ,  69.6 % completed\n",
      "LOSS: 0.5931609869003296 ACCURCY: 0.6857554816452898\n",
      "current epoch 349 ,  69.8 % completed\n",
      "LOSS: 0.5922401547431946 ACCURCY: 0.6860897903582486\n",
      "current epoch 350 ,  70.0 % completed\n",
      "LOSS: 0.608939528465271 ACCURCY: 0.6861155488721805\n",
      "current epoch 351 ,  70.2 % completed\n",
      "LOSS: 0.6074019074440002 ACCURCY: 0.6845029314462626\n",
      "current epoch 352 ,  70.4 % completed\n",
      "LOSS: 0.603939950466156 ACCURCY: 0.6860843272888103\n",
      "current epoch 353 ,  70.6 % completed\n",
      "LOSS: 0.5952597260475159 ACCURCY: 0.6865458575851394\n",
      "current epoch 354 ,  70.8 % completed\n",
      "LOSS: 0.5953714847564697 ACCURCY: 0.6847331729323307\n",
      "current epoch 355 ,  71.0 % completed\n",
      "LOSS: 0.6212979555130005 ACCURCY: 0.6853332401592218\n",
      "current epoch 356 ,  71.2 % completed\n",
      "LOSS: 0.6029564738273621 ACCURCY: 0.6858434816452895\n",
      "current epoch 357 ,  71.4 % completed\n",
      "LOSS: 0.6063628196716309 ACCURCY: 0.6832341795665634\n",
      "current epoch 358 ,  71.6 % completed\n",
      "LOSS: 0.6043427586555481 ACCURCY: 0.6837837098628925\n",
      "current epoch 359 ,  71.8 % completed\n",
      "LOSS: 0.5876944065093994 ACCURCY: 0.6857997098628925\n",
      "current epoch 360 ,  72.0 % completed\n",
      "LOSS: 0.6005241274833679 ACCURCY: 0.6869420858027422\n",
      "current epoch 361 ,  72.2 % completed\n",
      "LOSS: 0.591536819934845 ACCURCY: 0.6857243945157009\n",
      "current epoch 362 ,  72.4 % completed\n",
      "LOSS: 0.601348876953125 ACCURCY: 0.6833142467934543\n",
      "current epoch 363 ,  72.6 % completed\n",
      "LOSS: 0.6013930439949036 ACCURCY: 0.6861677098628927\n",
      "current epoch 364 ,  72.8 % completed\n",
      "LOSS: 0.6091493368148804 ACCURCY: 0.6857913206545776\n",
      "current epoch 365 ,  73.0 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6044137477874756 ACCURCY: 0.68491392481203\n",
      "current epoch 366 ,  73.2 % completed\n",
      "LOSS: 0.5969489216804504 ACCURCY: 0.6856401662980983\n",
      "current epoch 367 ,  73.4 % completed\n",
      "LOSS: 0.595675528049469 ACCURCY: 0.686348783724016\n",
      "current epoch 368 ,  73.6 % completed\n",
      "LOSS: 0.5973919630050659 ACCURCY: 0.6855399380804954\n",
      "current epoch 369 ,  73.8 % completed\n",
      "LOSS: 0.5921057462692261 ACCURCY: 0.6866544750110571\n",
      "current epoch 370 ,  74.0 % completed\n",
      "LOSS: 0.5945190787315369 ACCURCY: 0.6867959380804954\n",
      "current epoch 371 ,  74.2 % completed\n",
      "LOSS: 0.6005268096923828 ACCURCY: 0.6863210119416189\n",
      "current epoch 372 ,  74.4 % completed\n",
      "LOSS: 0.5902737379074097 ACCURCY: 0.6870940858027421\n",
      "current epoch 373 ,  74.6 % completed\n",
      "LOSS: 0.5941978096961975 ACCURCY: 0.6853925555064133\n",
      "current epoch 374 ,  74.8 % completed\n",
      "LOSS: 0.5956014394760132 ACCURCY: 0.6849374011499337\n",
      "current epoch 375 ,  75.0 % completed\n",
      "LOSS: 0.6080795526504517 ACCURCY: 0.686476394515701\n",
      "current epoch 376 ,  75.2 % completed\n",
      "LOSS: 0.5985790491104126 ACCURCY: 0.6866207837240159\n",
      "current epoch 377 ,  75.4 % completed\n",
      "LOSS: 0.5996289849281311 ACCURCY: 0.6865753206545776\n",
      "current epoch 378 ,  75.6 % completed\n",
      "LOSS: 0.6014652252197266 ACCURCY: 0.6860805555064132\n",
      "current epoch 379 ,  75.8 % completed\n",
      "LOSS: 0.5953479409217834 ACCURCY: 0.6856325555064131\n",
      "current epoch 380 ,  76.0 % completed\n",
      "LOSS: 0.603467583656311 ACCURCY: 0.6837832534276866\n",
      "current epoch 381 ,  76.2 % completed\n",
      "LOSS: 0.6040615439414978 ACCURCY: 0.6841234816452899\n",
      "current epoch 382 ,  76.4 % completed\n",
      "LOSS: 0.609249472618103 ACCURCY: 0.6824350252100841\n",
      "current epoch 383 ,  76.6 % completed\n",
      "LOSS: 0.5932908058166504 ACCURCY: 0.6853032534276867\n",
      "current epoch 384 ,  76.8 % completed\n",
      "LOSS: 0.6056588292121887 ACCURCY: 0.6866077098628925\n",
      "current epoch 385 ,  77.0 % completed\n",
      "LOSS: 0.5969655513763428 ACCURCY: 0.6824388642193719\n",
      "current epoch 386 ,  77.2 % completed\n",
      "LOSS: 0.6052460074424744 ACCURCY: 0.6845774011499337\n",
      "current epoch 387 ,  77.4 % completed\n",
      "LOSS: 0.5985792279243469 ACCURCY: 0.6837222467934544\n",
      "current epoch 388 ,  77.6 % completed\n",
      "LOSS: 0.593677282333374 ACCURCY: 0.6844308642193718\n",
      "current epoch 389 ,  77.8 % completed\n",
      "LOSS: 0.6013919115066528 ACCURCY: 0.6839108642193719\n",
      "current epoch 390 ,  78.0 % completed\n",
      "LOSS: 0.6055511236190796 ACCURCY: 0.6822503140203451\n",
      "current epoch 391 ,  78.2 % completed\n",
      "LOSS: 0.5871263146400452 ACCURCY: 0.6861567837240159\n",
      "current epoch 392 ,  78.4 % completed\n",
      "LOSS: 0.5903403162956238 ACCURCY: 0.6866278708536047\n",
      "current epoch 393 ,  78.6 % completed\n",
      "LOSS: 0.5929058194160461 ACCURCY: 0.6857045555064132\n",
      "current epoch 394 ,  78.8 % completed\n",
      "LOSS: 0.6049145460128784 ACCURCY: 0.685132394515701\n",
      "current epoch 395 ,  79.0 % completed\n",
      "LOSS: 0.5890673995018005 ACCURCY: 0.6859046899601947\n",
      "current epoch 396 ,  79.2 % completed\n",
      "LOSS: 0.6042133569717407 ACCURCY: 0.685358542237948\n",
      "current epoch 397 ,  79.4 % completed\n",
      "LOSS: 0.6087678670883179 ACCURCY: 0.6840505687748782\n",
      "current epoch 398 ,  79.6 % completed\n",
      "LOSS: 0.5987816452980042 ACCURCY: 0.6846299513489604\n",
      "current epoch 399 ,  79.8 % completed\n",
      "LOSS: 0.6076372265815735 ACCURCY: 0.6827967837240159\n",
      "current epoch 400 ,  80.0 % completed\n",
      "LOSS: 0.5923340320587158 ACCURCY: 0.6865989314462628\n",
      "current epoch 401 ,  80.2 % completed\n",
      "LOSS: 0.5882694721221924 ACCURCY: 0.685880944714728\n",
      "current epoch 402 ,  80.4 % completed\n",
      "LOSS: 0.59857177734375 ACCURCY: 0.6847230924369747\n",
      "current epoch 403 ,  80.6 % completed\n",
      "LOSS: 0.5924708247184753 ACCURCY: 0.6855849447147281\n",
      "current epoch 404 ,  80.8 % completed\n",
      "LOSS: 0.5918024778366089 ACCURCY: 0.6855226360017691\n",
      "current epoch 405 ,  81.0 % completed\n",
      "LOSS: 0.623358428478241 ACCURCY: 0.6861479380804952\n",
      "current epoch 406 ,  81.2 % completed\n",
      "FINISHED!!!\n",
      "LOSS: 0.5889992117881775 ACCURCY: 0.6842860185758515\n",
      "current epoch 407 ,  81.4 % completed\n"
     ]
    }
   ],
   "source": [
    "model1_trainingInfo = train(model1, criterion, train_loader, validation_loader, optimizer, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 trading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1852ada860>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = int(len(model1_trainingInfo[\"training_loss\"])/len(model1_trainingInfo[\"validation_accuracy\"]))\n",
    "plt.plot(model1_trainingInfo[\"training_loss\"][::steps], color = \"red\")\n",
    "plt.plot(model1_trainingInfo[\"validation_accuracy\"], color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"models//model1_2019.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_Model1(\n",
       "  (drop1): Dropout(p=0.1, inplace=False)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (channel1_l1): Linear(in_features=31, out_features=31, bias=True)\n",
       "  (channel1_l2): Linear(in_features=31, out_features=10, bias=True)\n",
       "  (channel1_l3): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (channel2_l1): Linear(in_features=31, out_features=31, bias=True)\n",
       "  (channel2_l2): Linear(in_features=31, out_features=10, bias=True)\n",
       "  (channel2_l3): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (out): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model1.state_dict(), path)\n",
    "model1.load_state_dict(torch.load(path))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carlos' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 31\n",
    "hidden1 = 31\n",
    "hidden2 = 10\n",
    "hidden3 = 5\n",
    "out_dim = 2\n",
    "\n",
    "modelCarlos = DNN_Carlos(input_dim, hidden1, hidden2, hidden3, out_dim)\n",
    "#model.to(\"cuda\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelCarlos.parameters(), lr=1e-4)\n",
    "\n",
    "training = TrainingData()\n",
    "testing = TestingData()\n",
    "train_loader = DataLoader(dataset = training, batch_size=2000, shuffle = True)\n",
    "validation_loader = DataLoader(dataset = testing, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_trainingInfo = trainMyModel(modelCarlos, criterion, train_loader, validation_loader, optimizer, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(len(model_trainingInfo[\"training_loss\"])/len(model_trainingInfo[\"validation_accuracy\"]))\n",
    "plt.plot(model_trainingInfo[\"training_loss\"][::steps], color = \"red\")\n",
    "plt.plot(model_trainingInfo[\"validation_accuracy\"], color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"models//modelCarlos_2019.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelCarlos.state_dict(), path)\n",
    "modelCarlos.load_state_dict(torch.load(path))\n",
    "modelCarlos.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 trading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246975, 33) (123972, 33)\n",
      "(246899, 33) (123906, 33)\n"
     ]
    }
   ],
   "source": [
    "START = \"2016-01-01\"\n",
    "MIDDLE = \"2018-01-01\"\n",
    "END = \"2019-01-01\"\n",
    "training_data = data[(data[\"Unnamed: 0.1\"] >= START) & (data[\"Unnamed: 0.1\"] < MIDDLE)]\n",
    "testing_data = data[(data[\"Unnamed: 0.1\"] >= MIDDLE) & (data[\"Unnamed: 0.1\"] < END)]\n",
    "print(training_data.shape, testing_data.shape)\n",
    "\n",
    "training_data = training_data.dropna()\n",
    "testing_data = testing_data.dropna()\n",
    "print(training_data.shape, testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_training = training_data['Label'].apply(lambda x: f(x))\n",
    "Y_testing = testing_data['Label'].apply(lambda x: f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.tensor(training_data[columns].values).float()\n",
    "        self.y = torch.tensor(Y_training.values).long()\n",
    "        self.len = self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class TestingData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.tensor(testing_data[columns].values).float()\n",
    "        self.y = torch.tensor(Y_testing.values).long()\n",
    "        self.len = self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 31\n",
    "hidden1 = 31\n",
    "hidden2 = 10\n",
    "hidden3 = 5\n",
    "out_dim = 2\n",
    "\n",
    "model1 = DNN_Model1(input_dim, hidden1, hidden2, hidden3, out_dim)\n",
    "#model1.to(\"cuda\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model1.parameters())\n",
    "\n",
    "training = TrainingData()\n",
    "testing = TestingData()\n",
    "train_loader = DataLoader(dataset = training, batch_size=2000, shuffle = True)\n",
    "validation_loader = DataLoader(dataset = testing, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs582/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.697980523109436 ACCURCY: 0.5145136098310291\n",
      "current epoch 1 ,  0.2 % completed\n",
      "LOSS: 0.69368577003479 ACCURCY: 0.5218086799795186\n",
      "current epoch 2 ,  0.4 % completed\n",
      "LOSS: 0.691882312297821 ACCURCY: 0.5272867875064006\n",
      "current epoch 3 ,  0.6 % completed\n",
      "LOSS: 0.6961421966552734 ACCURCY: 0.53517385765489\n",
      "current epoch 4 ,  0.8 % completed\n",
      "LOSS: 0.6924892067909241 ACCURCY: 0.5491489278033793\n",
      "current epoch 5 ,  1.0 % completed\n",
      "LOSS: 0.6819688677787781 ACCURCY: 0.5637185540194573\n",
      "current epoch 6 ,  1.2 % completed\n",
      "LOSS: 0.6845780611038208 ACCURCY: 0.5870482293906811\n",
      "current epoch 7 ,  1.4 % completed\n",
      "LOSS: 0.6614798903465271 ACCURCY: 0.6243712155657962\n",
      "current epoch 8 ,  1.6 % completed\n",
      "LOSS: 0.6525678634643555 ACCURCY: 0.6476160614439322\n",
      "current epoch 9 ,  1.8 % completed\n",
      "LOSS: 0.6632350087165833 ACCURCY: 0.6337936385048643\n",
      "current epoch 10 ,  2.0 % completed\n",
      "LOSS: 0.6345789432525635 ACCURCY: 0.623516841781874\n",
      "current epoch 11 ,  2.2 % completed\n",
      "LOSS: 0.6615710258483887 ACCURCY: 0.6699374214029697\n",
      "current epoch 12 ,  2.4 % completed\n",
      "LOSS: 0.6083722114562988 ACCURCY: 0.6513571899641577\n",
      "current epoch 13 ,  2.6 % completed\n",
      "LOSS: 0.6197366714477539 ACCURCY: 0.646881986687148\n",
      "current epoch 14 ,  2.8 % completed\n",
      "LOSS: 0.6380323767662048 ACCURCY: 0.6443447250384026\n",
      "current epoch 15 ,  3.0 % completed\n",
      "LOSS: 0.6215848326683044 ACCURCY: 0.6612327414234512\n",
      "current epoch 16 ,  3.2 % completed\n",
      "LOSS: 0.6171022653579712 ACCURCY: 0.6560762601126473\n",
      "current epoch 17 ,  3.4 % completed\n",
      "LOSS: 0.6132072806358337 ACCURCY: 0.6751783840245775\n",
      "current epoch 18 ,  3.6 % completed\n",
      "LOSS: 0.6022871136665344 ACCURCY: 0.6697188489503327\n",
      "current epoch 19 ,  3.8 % completed\n",
      "LOSS: 0.5982850790023804 ACCURCY: 0.6742692718894009\n",
      "current epoch 20 ,  4.0 % completed\n",
      "LOSS: 0.6276746988296509 ACCURCY: 0.6622525919098823\n",
      "current epoch 21 ,  4.2 % completed\n",
      "LOSS: 0.6052274107933044 ACCURCY: 0.6632922764976956\n",
      "current epoch 22 ,  4.4 % completed\n",
      "LOSS: 0.6056820154190063 ACCURCY: 0.6658327578084997\n",
      "current epoch 23 ,  4.6 % completed\n",
      "LOSS: 0.6091902852058411 ACCURCY: 0.6757006246799796\n",
      "current epoch 24 ,  4.8 % completed\n",
      "LOSS: 0.6045570373535156 ACCURCY: 0.6765681433691755\n",
      "current epoch 25 ,  5.0 % completed\n",
      "LOSS: 0.5934472680091858 ACCURCY: 0.6754129564772146\n",
      "current epoch 26 ,  5.2 % completed\n",
      "LOSS: 0.6143490076065063 ACCURCY: 0.676015827956989\n",
      "current epoch 27 ,  5.4 % completed\n",
      "LOSS: 0.6132927536964417 ACCURCY: 0.6554132063492064\n",
      "current epoch 28 ,  5.6 % completed\n",
      "LOSS: 0.5864424109458923 ACCURCY: 0.6691284423963133\n",
      "current epoch 29 ,  5.8 % completed\n",
      "LOSS: 0.5972382426261902 ACCURCY: 0.6764212718894009\n",
      "current epoch 30 ,  6.0 % completed\n",
      "LOSS: 0.5925030708312988 ACCURCY: 0.673904458781362\n",
      "current epoch 31 ,  6.2 % completed\n",
      "LOSS: 0.5934138894081116 ACCURCY: 0.6743991807475679\n",
      "current epoch 32 ,  6.4 % completed\n",
      "LOSS: 0.6078686714172363 ACCURCY: 0.6760798279569893\n",
      "current epoch 33 ,  6.6 % completed\n",
      "LOSS: 0.6011732816696167 ACCURCY: 0.6716273302611365\n",
      "current epoch 34 ,  6.8 % completed\n",
      "LOSS: 0.6043747663497925 ACCURCY: 0.6744926082949309\n",
      "current epoch 35 ,  7.0 % completed\n",
      "LOSS: 0.6070356369018555 ACCURCY: 0.6776347322068612\n",
      "current epoch 36 ,  7.2 % completed\n",
      "LOSS: 0.5983503460884094 ACCURCY: 0.677401122375832\n",
      "current epoch 37 ,  7.4 % completed\n",
      "LOSS: 0.6109773516654968 ACCURCY: 0.6762007905785969\n",
      "current epoch 38 ,  7.6 % completed\n",
      "LOSS: 0.613014280796051 ACCURCY: 0.6742391807475678\n",
      "current epoch 39 ,  7.8 % completed\n",
      "LOSS: 0.6033329367637634 ACCURCY: 0.6737774214029699\n",
      "current epoch 40 ,  8.0 % completed\n",
      "LOSS: 0.6146702170372009 ACCURCY: 0.678063512544803\n",
      "current epoch 41 ,  8.2 % completed\n",
      "LOSS: 0.6058148741722107 ACCURCY: 0.6700087741935482\n",
      "current epoch 42 ,  8.4 % completed\n",
      "LOSS: 0.5996034145355225 ACCURCY: 0.6777755125448031\n",
      "current epoch 43 ,  8.6 % completed\n",
      "LOSS: 0.6158933043479919 ACCURCY: 0.6788456036866358\n",
      "current epoch 44 ,  8.8 % completed\n",
      "LOSS: 0.6126679182052612 ACCURCY: 0.6772958279569893\n",
      "current epoch 45 ,  9.0 % completed\n",
      "LOSS: 0.5969685316085815 ACCURCY: 0.671963662058372\n",
      "current epoch 46 ,  9.2 % completed\n",
      "LOSS: 0.6041738986968994 ACCURCY: 0.6748036620583717\n",
      "current epoch 47 ,  9.4 % completed\n",
      "LOSS: 0.5809374451637268 ACCURCY: 0.6787697695852535\n",
      "current epoch 48 ,  9.6 % completed\n",
      "LOSS: 0.6122586131095886 ACCURCY: 0.6724219027137737\n",
      "current epoch 49 ,  9.8 % completed\n",
      "LOSS: 0.6006279587745667 ACCURCY: 0.6770308653353814\n",
      "current epoch 50 ,  10.0 % completed\n",
      "LOSS: 0.6041299700737 ACCURCY: 0.6792196784434203\n",
      "current epoch 51 ,  10.2 % completed\n",
      "LOSS: 0.5929216146469116 ACCURCY: 0.677022549923195\n",
      "current epoch 52 ,  10.4 % completed\n",
      "LOSS: 0.6058966517448425 ACCURCY: 0.6710026994367638\n",
      "current epoch 53 ,  10.6 % completed\n",
      "LOSS: 0.5957401394844055 ACCURCY: 0.6802699190988223\n",
      "current epoch 54 ,  10.8 % completed\n",
      "LOSS: 0.5868623852729797 ACCURCY: 0.67700621812596\n",
      "current epoch 55 ,  11.0 % completed\n",
      "LOSS: 0.5867500305175781 ACCURCY: 0.679510549923195\n",
      "current epoch 56 ,  11.2 % completed\n",
      "LOSS: 0.608262836933136 ACCURCY: 0.6796180849974399\n",
      "current epoch 57 ,  11.4 % completed\n",
      "LOSS: 0.5917701125144958 ACCURCY: 0.6793307158218126\n",
      "current epoch 58 ,  11.6 % completed\n",
      "LOSS: 0.5968932509422302 ACCURCY: 0.6782116784434202\n",
      "current epoch 59 ,  11.8 % completed\n",
      "LOSS: 0.5965284109115601 ACCURCY: 0.678968790578597\n",
      "current epoch 60 ,  12.0 % completed\n",
      "LOSS: 0.6085755228996277 ACCURCY: 0.6756852555043522\n",
      "current epoch 61 ,  12.2 % completed\n",
      "LOSS: 0.6028079986572266 ACCURCY: 0.678583844342038\n",
      "current epoch 62 ,  12.4 % completed\n",
      "LOSS: 0.6028552651405334 ACCURCY: 0.675600458781362\n",
      "current epoch 63 ,  12.6 % completed\n",
      "LOSS: 0.5985524654388428 ACCURCY: 0.673391180747568\n",
      "current epoch 64 ,  12.8 % completed\n",
      "LOSS: 0.6063642501831055 ACCURCY: 0.6680426830517152\n",
      "current epoch 65 ,  13.0 % completed\n",
      "LOSS: 0.6084085702896118 ACCURCY: 0.6778321597542242\n",
      "current epoch 66 ,  13.2 % completed\n",
      "LOSS: 0.6072201132774353 ACCURCY: 0.6793998279569893\n",
      "current epoch 67 ,  13.4 % completed\n",
      "LOSS: 0.5949829816818237 ACCURCY: 0.6740100522273424\n",
      "current epoch 68 ,  13.6 % completed\n",
      "LOSS: 0.611613929271698 ACCURCY: 0.6796433630312341\n",
      "current epoch 69 ,  13.8 % completed\n",
      "LOSS: 0.5969625115394592 ACCURCY: 0.6780369564772144\n",
      "current epoch 70 ,  14.0 % completed\n",
      "LOSS: 0.5982282757759094 ACCURCY: 0.677591512544803\n",
      "current epoch 71 ,  14.2 % completed\n",
      "LOSS: 0.5769230127334595 ACCURCY: 0.6775537532002047\n",
      "current epoch 72 ,  14.4 % completed\n",
      "LOSS: 0.6096906661987305 ACCURCY: 0.6792289564772146\n",
      "current epoch 73 ,  14.6 % completed\n",
      "LOSS: 0.593559205532074 ACCURCY: 0.6791751971326164\n",
      "current epoch 74 ,  14.8 % completed\n",
      "LOSS: 0.5977970957756042 ACCURCY: 0.6795563092677932\n",
      "current epoch 75 ,  15.0 % completed\n",
      "LOSS: 0.5969240069389343 ACCURCY: 0.6773137532002049\n",
      "current epoch 76 ,  15.2 % completed\n",
      "LOSS: 0.5978649258613586 ACCURCY: 0.6793422345110086\n",
      "current epoch 77 ,  15.4 % completed\n",
      "LOSS: 0.5763910412788391 ACCURCY: 0.6781387158218126\n",
      "current epoch 78 ,  15.6 % completed\n",
      "LOSS: 0.601324737071991 ACCURCY: 0.6749911807475679\n",
      "current epoch 79 ,  15.8 % completed\n",
      "LOSS: 0.5994318723678589 ACCURCY: 0.6731409400921659\n",
      "current epoch 80 ,  16.0 % completed\n",
      "LOSS: 0.5998870730400085 ACCURCY: 0.6771060686123911\n",
      "current epoch 81 ,  16.2 % completed\n",
      "LOSS: 0.6039596796035767 ACCURCY: 0.6794584004096262\n",
      "current epoch 82 ,  16.4 % completed\n",
      "LOSS: 0.5857612490653992 ACCURCY: 0.6799934377880186\n",
      "current epoch 83 ,  16.6 % completed\n",
      "LOSS: 0.6120575070381165 ACCURCY: 0.678900641065028\n",
      "current epoch 84 ,  16.8 % completed\n",
      "LOSS: 0.594336211681366 ACCURCY: 0.6771649564772146\n",
      "current epoch 85 ,  17.0 % completed\n",
      "LOSS: 0.5898877382278442 ACCURCY: 0.6788395289298514\n",
      "current epoch 86 ,  17.2 % completed\n",
      "LOSS: 0.6125572323799133 ACCURCY: 0.6789611223758318\n",
      "current epoch 87 ,  17.4 % completed\n",
      "LOSS: 0.6043638586997986 ACCURCY: 0.6791473630312339\n",
      "current epoch 88 ,  17.6 % completed\n",
      "LOSS: 0.5785710215568542 ACCURCY: 0.6794814377880186\n",
      "current epoch 89 ,  17.8 % completed\n",
      "LOSS: 0.5979021191596985 ACCURCY: 0.6782791971326163\n",
      "current epoch 90 ,  18.0 % completed\n",
      "LOSS: 0.598659098148346 ACCURCY: 0.6772334214029698\n",
      "current epoch 91 ,  18.2 % completed\n",
      "LOSS: 0.6178129315376282 ACCURCY: 0.6797563256528417\n",
      "current epoch 92 ,  18.4 % completed\n",
      "LOSS: 0.5857117176055908 ACCURCY: 0.6792087905785971\n",
      "current epoch 93 ,  18.6 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6038559079170227 ACCURCY: 0.6776347158218126\n",
      "current epoch 94 ,  18.8 % completed\n",
      "LOSS: 0.5926951169967651 ACCURCY: 0.6794488069636456\n",
      "current epoch 95 ,  19.0 % completed\n",
      "LOSS: 0.6013010740280151 ACCURCY: 0.6795972882744497\n",
      "current epoch 96 ,  19.2 % completed\n",
      "LOSS: 0.6059600710868835 ACCURCY: 0.6797351971326164\n",
      "current epoch 97 ,  19.4 % completed\n",
      "LOSS: 0.6008602380752563 ACCURCY: 0.6806478443420378\n",
      "current epoch 98 ,  19.6 % completed\n",
      "LOSS: 0.5876300930976868 ACCURCY: 0.6797793630312339\n",
      "current epoch 99 ,  19.8 % completed\n",
      "LOSS: 0.611396074295044 ACCURCY: 0.6793713630312339\n",
      "current epoch 100 ,  20.0 % completed\n",
      "LOSS: 0.5803301930427551 ACCURCY: 0.6769582345110088\n",
      "current epoch 101 ,  20.2 % completed\n",
      "LOSS: 0.5851761102676392 ACCURCY: 0.6788535873015873\n",
      "current epoch 102 ,  20.4 % completed\n",
      "LOSS: 0.5844557881355286 ACCURCY: 0.6744676620583718\n",
      "current epoch 103 ,  20.6 % completed\n",
      "LOSS: 0.600889265537262 ACCURCY: 0.679773935483871\n",
      "current epoch 104 ,  20.8 % completed\n",
      "LOSS: 0.6165308356285095 ACCURCY: 0.6793540849974399\n",
      "current epoch 105 ,  21.0 % completed\n",
      "LOSS: 0.5835106372833252 ACCURCY: 0.6780161597542244\n",
      "current epoch 106 ,  21.2 % completed\n",
      "LOSS: 0.6167676448822021 ACCURCY: 0.6798827158218126\n",
      "current epoch 107 ,  21.4 % completed\n",
      "LOSS: 0.587608277797699 ACCURCY: 0.677227031233999\n",
      "current epoch 108 ,  21.6 % completed\n",
      "LOSS: 0.585358202457428 ACCURCY: 0.6793291223758321\n",
      "current epoch 109 ,  21.8 % completed\n",
      "LOSS: 0.602068305015564 ACCURCY: 0.6712513302611367\n",
      "current epoch 110 ,  22.0 % completed\n",
      "LOSS: 0.5987967252731323 ACCURCY: 0.6779249564772145\n",
      "current epoch 111 ,  22.2 % completed\n",
      "LOSS: 0.5948359966278076 ACCURCY: 0.6788753630312339\n",
      "current epoch 112 ,  22.4 % completed\n",
      "LOSS: 0.6088178157806396 ACCURCY: 0.6772279938556067\n",
      "current epoch 113 ,  22.6 % completed\n",
      "LOSS: 0.6083916425704956 ACCURCY: 0.6772084751664106\n",
      "current epoch 114 ,  22.8 % completed\n",
      "LOSS: 0.6043685674667358 ACCURCY: 0.6788267158218126\n",
      "current epoch 115 ,  23.0 % completed\n",
      "LOSS: 0.5893107652664185 ACCURCY: 0.6757041597542242\n",
      "current epoch 116 ,  23.2 % completed\n",
      "LOSS: 0.6330183744430542 ACCURCY: 0.6791774377880185\n",
      "current epoch 117 ,  23.4 % completed\n",
      "LOSS: 0.5871323943138123 ACCURCY: 0.6758372882744496\n",
      "current epoch 118 ,  23.6 % completed\n",
      "LOSS: 0.6103857159614563 ACCURCY: 0.6794148817204301\n",
      "current epoch 119 ,  23.8 % completed\n",
      "LOSS: 0.5861057043075562 ACCURCY: 0.6789342345110088\n",
      "current epoch 120 ,  24.0 % completed\n",
      "LOSS: 0.5958911776542664 ACCURCY: 0.6784011059907833\n",
      "current epoch 121 ,  24.2 % completed\n",
      "LOSS: 0.605522632598877 ACCURCY: 0.6772491059907833\n",
      "current epoch 122 ,  24.4 % completed\n",
      "LOSS: 0.5967225432395935 ACCURCY: 0.6758516620583717\n",
      "current epoch 123 ,  24.6 % completed\n",
      "LOSS: 0.6032012701034546 ACCURCY: 0.6790808069636456\n",
      "current epoch 124 ,  24.8 % completed\n",
      "LOSS: 0.5795321464538574 ACCURCY: 0.6797620849974397\n",
      "current epoch 125 ,  25.0 % completed\n",
      "LOSS: 0.599423348903656 ACCURCY: 0.6781639938556068\n",
      "current epoch 126 ,  25.2 % completed\n",
      "LOSS: 0.5941898822784424 ACCURCY: 0.6762686246799795\n",
      "current epoch 127 ,  25.4 % completed\n",
      "LOSS: 0.5819994807243347 ACCURCY: 0.6759991807475678\n",
      "current epoch 128 ,  25.6 % completed\n",
      "LOSS: 0.5972905158996582 ACCURCY: 0.675936790578597\n",
      "current epoch 129 ,  25.8 % completed\n",
      "LOSS: 0.6081490516662598 ACCURCY: 0.6795940849974399\n",
      "current epoch 130 ,  26.0 % completed\n",
      "LOSS: 0.6303998827934265 ACCURCY: 0.6802939190988225\n",
      "current epoch 131 ,  26.2 % completed\n",
      "LOSS: 0.6026197671890259 ACCURCY: 0.6790049564772146\n",
      "current epoch 132 ,  26.4 % completed\n",
      "LOSS: 0.616398274898529 ACCURCY: 0.6801969728622632\n",
      "current epoch 133 ,  26.6 % completed\n",
      "LOSS: 0.5977372527122498 ACCURCY: 0.6784836784434205\n",
      "current epoch 134 ,  26.8 % completed\n",
      "LOSS: 0.5874761343002319 ACCURCY: 0.6765195125448029\n",
      "current epoch 135 ,  27.0 % completed\n",
      "LOSS: 0.5918869376182556 ACCURCY: 0.6779227158218126\n",
      "current epoch 136 ,  27.2 % completed\n",
      "LOSS: 0.5969982743263245 ACCURCY: 0.6765335873015874\n",
      "current epoch 137 ,  27.4 % completed\n",
      "LOSS: 0.608470618724823 ACCURCY: 0.6759799938556068\n",
      "current epoch 138 ,  27.6 % completed\n",
      "LOSS: 0.6014959812164307 ACCURCY: 0.6773524751664105\n",
      "current epoch 139 ,  27.8 % completed\n",
      "LOSS: 0.6053277254104614 ACCURCY: 0.6793067322068613\n",
      "current epoch 140 ,  28.0 % completed\n",
      "LOSS: 0.5968661308288574 ACCURCY: 0.679723363031234\n",
      "current epoch 141 ,  28.2 % completed\n",
      "LOSS: 0.6101709604263306 ACCURCY: 0.6806961597542244\n",
      "current epoch 142 ,  28.4 % completed\n",
      "LOSS: 0.5961229801177979 ACCURCY: 0.6792363256528418\n",
      "current epoch 143 ,  28.6 % completed\n",
      "LOSS: 0.5911056995391846 ACCURCY: 0.6741550148489505\n",
      "current epoch 144 ,  28.8 % completed\n",
      "LOSS: 0.5963278412818909 ACCURCY: 0.6772769564772146\n",
      "current epoch 145 ,  29.0 % completed\n",
      "LOSS: 0.60631263256073 ACCURCY: 0.6683911643625194\n",
      "current epoch 146 ,  29.2 % completed\n",
      "LOSS: 0.5974762439727783 ACCURCY: 0.6797921597542244\n",
      "current epoch 147 ,  29.4 % completed\n",
      "LOSS: 0.5997018814086914 ACCURCY: 0.679443363031234\n",
      "current epoch 148 ,  29.6 % completed\n",
      "LOSS: 0.617811918258667 ACCURCY: 0.6796168069636457\n",
      "current epoch 149 ,  29.8 % completed\n",
      "LOSS: 0.6033974885940552 ACCURCY: 0.6794977695852534\n",
      "current epoch 150 ,  30.0 % completed\n",
      "LOSS: 0.5940062403678894 ACCURCY: 0.6763927905785969\n",
      "current epoch 151 ,  30.2 % completed\n",
      "LOSS: 0.6014265418052673 ACCURCY: 0.6790391971326166\n",
      "current epoch 152 ,  30.4 % completed\n",
      "LOSS: 0.5916380882263184 ACCURCY: 0.6801544004096263\n",
      "current epoch 153 ,  30.6 % completed\n",
      "LOSS: 0.607890248298645 ACCURCY: 0.679500641065028\n",
      "current epoch 154 ,  30.8 % completed\n",
      "LOSS: 0.6067872643470764 ACCURCY: 0.6794151971326166\n",
      "current epoch 155 ,  31.0 % completed\n",
      "LOSS: 0.5945048332214355 ACCURCY: 0.676042699436764\n",
      "current epoch 156 ,  31.2 % completed\n",
      "LOSS: 0.5924286246299744 ACCURCY: 0.6790897532002047\n",
      "current epoch 157 ,  31.4 % completed\n",
      "LOSS: 0.5941259860992432 ACCURCY: 0.679729122375832\n",
      "current epoch 158 ,  31.6 % completed\n",
      "LOSS: 0.593635082244873 ACCURCY: 0.6786782345110086\n",
      "current epoch 159 ,  31.8 % completed\n",
      "LOSS: 0.5956913828849792 ACCURCY: 0.6691082928827445\n",
      "current epoch 160 ,  32.0 % completed\n",
      "LOSS: 0.5659576058387756 ACCURCY: 0.6771463840245775\n",
      "current epoch 161 ,  32.2 % completed\n",
      "LOSS: 0.5986766815185547 ACCURCY: 0.6789115125448031\n",
      "current epoch 162 ,  32.4 % completed\n",
      "LOSS: 0.605766236782074 ACCURCY: 0.6787332718894009\n",
      "current epoch 163 ,  32.6 % completed\n",
      "LOSS: 0.6073393225669861 ACCURCY: 0.6794427158218125\n",
      "current epoch 164 ,  32.8 % completed\n",
      "LOSS: 0.6188241243362427 ACCURCY: 0.6723342017409112\n",
      "current epoch 165 ,  33.0 % completed\n",
      "LOSS: 0.6031702160835266 ACCURCY: 0.6743195125448029\n",
      "current epoch 166 ,  33.2 % completed\n",
      "LOSS: 0.6094177961349487 ACCURCY: 0.67905808499744\n",
      "current epoch 167 ,  33.4 % completed\n",
      "LOSS: 0.6046531200408936 ACCURCY: 0.6794068817204301\n",
      "current epoch 168 ,  33.6 % completed\n",
      "LOSS: 0.6062731146812439 ACCURCY: 0.6730481433691757\n",
      "current epoch 169 ,  33.8 % completed\n",
      "LOSS: 0.5873718857765198 ACCURCY: 0.6793121597542242\n",
      "current epoch 170 ,  34.0 % completed\n",
      "LOSS: 0.6002858877182007 ACCURCY: 0.6786651059907833\n",
      "current epoch 171 ,  34.2 % completed\n",
      "LOSS: 0.5661889314651489 ACCURCY: 0.6779768069636457\n",
      "current epoch 172 ,  34.4 % completed\n",
      "LOSS: 0.5973185896873474 ACCURCY: 0.6788462345110088\n",
      "current epoch 173 ,  34.6 % completed\n",
      "LOSS: 0.6040450930595398 ACCURCY: 0.6784958279569893\n",
      "current epoch 174 ,  34.8 % completed\n",
      "LOSS: 0.5887976884841919 ACCURCY: 0.6786184004096262\n",
      "current epoch 175 ,  35.0 % completed\n",
      "LOSS: 0.5967707633972168 ACCURCY: 0.6796158443420378\n",
      "current epoch 176 ,  35.2 % completed\n",
      "LOSS: 0.607804000377655 ACCURCY: 0.6794868981054788\n",
      "current epoch 177 ,  35.4 % completed\n",
      "LOSS: 0.600520670413971 ACCURCY: 0.677840790578597\n",
      "current epoch 178 ,  35.6 % completed\n",
      "LOSS: 0.6011572480201721 ACCURCY: 0.67994288172043\n",
      "current epoch 179 ,  35.8 % completed\n",
      "LOSS: 0.6002961993217468 ACCURCY: 0.6781224004096262\n",
      "current epoch 180 ,  36.0 % completed\n",
      "LOSS: 0.5791419148445129 ACCURCY: 0.680337454173067\n",
      "current epoch 181 ,  36.2 % completed\n",
      "LOSS: 0.5969591736793518 ACCURCY: 0.6798196784434205\n",
      "current epoch 182 ,  36.4 % completed\n",
      "LOSS: 0.5963881611824036 ACCURCY: 0.6796657695852537\n",
      "current epoch 183 ,  36.6 % completed\n",
      "LOSS: 0.5974515080451965 ACCURCY: 0.6779831971326163\n",
      "current epoch 184 ,  36.8 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6045175194740295 ACCURCY: 0.6795825499231951\n",
      "current epoch 185 ,  37.0 % completed\n",
      "LOSS: 0.5969266295433044 ACCURCY: 0.6773691059907834\n",
      "current epoch 186 ,  37.2 % completed\n",
      "LOSS: 0.6117079854011536 ACCURCY: 0.6802568069636457\n",
      "current epoch 187 ,  37.4 % completed\n",
      "LOSS: 0.5873275995254517 ACCURCY: 0.6781729564772145\n",
      "current epoch 188 ,  37.6 % completed\n",
      "LOSS: 0.5975785255432129 ACCURCY: 0.6798068817204301\n",
      "current epoch 189 ,  37.8 % completed\n",
      "LOSS: 0.604917049407959 ACCURCY: 0.6794424004096261\n",
      "current epoch 190 ,  38.0 % completed\n",
      "LOSS: 0.602888286113739 ACCURCY: 0.6785879938556065\n",
      "current epoch 191 ,  38.2 % completed\n",
      "LOSS: 0.6009770631790161 ACCURCY: 0.679149603686636\n",
      "current epoch 192 ,  38.4 % completed\n",
      "LOSS: 0.5951805114746094 ACCURCY: 0.6807211223758319\n",
      "current epoch 193 ,  38.6 % completed\n",
      "LOSS: 0.587699830532074 ACCURCY: 0.6802936036866359\n",
      "current epoch 194 ,  38.8 % completed\n",
      "LOSS: 0.6127668023109436 ACCURCY: 0.675280790578597\n",
      "current epoch 195 ,  39.0 % completed\n",
      "LOSS: 0.6006763577461243 ACCURCY: 0.6794856036866358\n",
      "current epoch 196 ,  39.2 % completed\n",
      "LOSS: 0.5898261070251465 ACCURCY: 0.6802417532002049\n",
      "current epoch 197 ,  39.4 % completed\n",
      "LOSS: 0.5963865518569946 ACCURCY: 0.6800951971326163\n",
      "current epoch 198 ,  39.6 % completed\n",
      "LOSS: 0.6006221175193787 ACCURCY: 0.6792958443420379\n",
      "current epoch 199 ,  39.8 % completed\n",
      "LOSS: 0.6011337041854858 ACCURCY: 0.6793070312339989\n",
      "current epoch 200 ,  40.0 % completed\n",
      "LOSS: 0.5843756198883057 ACCURCY: 0.6791883256528418\n",
      "current epoch 201 ,  40.2 % completed\n",
      "LOSS: 0.5877580046653748 ACCURCY: 0.6735300522273425\n",
      "current epoch 202 ,  40.4 % completed\n",
      "LOSS: 0.5734657049179077 ACCURCY: 0.6795540849974399\n",
      "current epoch 203 ,  40.6 % completed\n",
      "LOSS: 0.6085907816886902 ACCURCY: 0.6791054377880187\n",
      "current epoch 204 ,  40.8 % completed\n",
      "LOSS: 0.5999102592468262 ACCURCY: 0.68011408499744\n",
      "current epoch 205 ,  41.0 % completed\n",
      "LOSS: 0.6189692616462708 ACCURCY: 0.6778203092677932\n",
      "current epoch 206 ,  41.2 % completed\n",
      "LOSS: 0.6066440939903259 ACCURCY: 0.6761799938556068\n",
      "current epoch 207 ,  41.4 % completed\n",
      "LOSS: 0.6092967391014099 ACCURCY: 0.6746836456733231\n",
      "current epoch 208 ,  41.6 % completed\n",
      "LOSS: 0.5949458479881287 ACCURCY: 0.6787764751664106\n",
      "current epoch 209 ,  41.8 % completed\n",
      "LOSS: 0.5926591753959656 ACCURCY: 0.6792910476190477\n",
      "current epoch 210 ,  42.0 % completed\n",
      "LOSS: 0.609980046749115 ACCURCY: 0.6792856036866359\n",
      "current epoch 211 ,  42.2 % completed\n",
      "LOSS: 0.5916787981987 ACCURCY: 0.6754154961597543\n",
      "current epoch 212 ,  42.4 % completed\n",
      "LOSS: 0.5897460579872131 ACCURCY: 0.6774772718894009\n",
      "current epoch 213 ,  42.6 % completed\n",
      "LOSS: 0.5987623929977417 ACCURCY: 0.679938400409626\n",
      "current epoch 214 ,  42.8 % completed\n",
      "LOSS: 0.5927101969718933 ACCURCY: 0.6787806246799795\n",
      "current epoch 215 ,  43.0 % completed\n",
      "LOSS: 0.5871431827545166 ACCURCY: 0.6795425663082437\n",
      "current epoch 216 ,  43.2 % completed\n",
      "LOSS: 0.6107694506645203 ACCURCY: 0.6786180686123912\n",
      "current epoch 217 ,  43.4 % completed\n",
      "LOSS: 0.588988721370697 ACCURCY: 0.6754580686123913\n",
      "current epoch 218 ,  43.6 % completed\n",
      "LOSS: 0.5977326035499573 ACCURCY: 0.677859993855607\n",
      "current epoch 219 ,  43.8 % completed\n",
      "LOSS: 0.6068927049636841 ACCURCY: 0.6767457532002049\n",
      "current epoch 220 ,  44.0 % completed\n",
      "LOSS: 0.5881791710853577 ACCURCY: 0.6792631971326165\n",
      "current epoch 221 ,  44.2 % completed\n",
      "LOSS: 0.5938869118690491 ACCURCY: 0.6788097532002049\n",
      "current epoch 222 ,  44.4 % completed\n",
      "LOSS: 0.5828813910484314 ACCURCY: 0.6805064004096263\n",
      "current epoch 223 ,  44.6 % completed\n",
      "LOSS: 0.601005494594574 ACCURCY: 0.6782811223758319\n",
      "current epoch 224 ,  44.8 % completed\n",
      "LOSS: 0.6009600162506104 ACCURCY: 0.6746964587813619\n",
      "current epoch 225 ,  45.0 % completed\n",
      "LOSS: 0.586743950843811 ACCURCY: 0.6780910312339989\n",
      "current epoch 226 ,  45.2 % completed\n",
      "LOSS: 0.5934436917304993 ACCURCY: 0.6764609400921658\n",
      "current epoch 227 ,  45.4 % completed\n",
      "LOSS: 0.5905923247337341 ACCURCY: 0.6788043256528418\n",
      "current epoch 228 ,  45.6 % completed\n",
      "LOSS: 0.6192527413368225 ACCURCY: 0.6800584004096263\n",
      "current epoch 229 ,  45.8 % completed\n",
      "LOSS: 0.6149659156799316 ACCURCY: 0.6769742345110086\n",
      "current epoch 230 ,  46.0 % completed\n",
      "LOSS: 0.5761803984642029 ACCURCY: 0.6773892718894008\n",
      "current epoch 231 ,  46.2 % completed\n",
      "LOSS: 0.5817652940750122 ACCURCY: 0.678889122375832\n",
      "current epoch 232 ,  46.4 % completed\n",
      "LOSS: 0.608635663986206 ACCURCY: 0.6742820686123911\n",
      "current epoch 233 ,  46.6 % completed\n",
      "LOSS: 0.5880043506622314 ACCURCY: 0.6717137368151562\n",
      "current epoch 234 ,  46.8 % completed\n",
      "LOSS: 0.6049287915229797 ACCURCY: 0.6793624004096261\n",
      "current epoch 235 ,  47.0 % completed\n",
      "LOSS: 0.5914958119392395 ACCURCY: 0.6793419190988225\n",
      "current epoch 236 ,  47.2 % completed\n",
      "LOSS: 0.5864400863647461 ACCURCY: 0.6778142345110086\n",
      "current epoch 237 ,  47.4 % completed\n",
      "LOSS: 0.5991984009742737 ACCURCY: 0.6801038607270865\n",
      "current epoch 238 ,  47.6 % completed\n",
      "LOSS: 0.6095593571662903 ACCURCY: 0.6805403256528417\n",
      "current epoch 239 ,  47.8 % completed\n",
      "LOSS: 0.5883103013038635 ACCURCY: 0.6800724751664106\n",
      "current epoch 240 ,  48.0 % completed\n",
      "LOSS: 0.5899868011474609 ACCURCY: 0.6786196784434204\n",
      "current epoch 241 ,  48.2 % completed\n",
      "LOSS: 0.5985214114189148 ACCURCY: 0.6750874961597543\n",
      "current epoch 242 ,  48.4 % completed\n",
      "LOSS: 0.6005348563194275 ACCURCY: 0.6796059190988224\n",
      "current epoch 243 ,  48.6 % completed\n",
      "LOSS: 0.5888585448265076 ACCURCY: 0.6788375873015872\n",
      "current epoch 244 ,  48.8 % completed\n",
      "LOSS: 0.6009489297866821 ACCURCY: 0.6805512135176653\n",
      "current epoch 245 ,  49.0 % completed\n",
      "LOSS: 0.6100660562515259 ACCURCY: 0.6765278279569891\n",
      "current epoch 246 ,  49.2 % completed\n",
      "LOSS: 0.6083390712738037 ACCURCY: 0.6798689564772143\n",
      "current epoch 247 ,  49.4 % completed\n",
      "LOSS: 0.6017864346504211 ACCURCY: 0.6683329237071173\n",
      "current epoch 248 ,  49.6 % completed\n",
      "LOSS: 0.6168287396430969 ACCURCY: 0.680493935483871\n",
      "current epoch 249 ,  49.8 % completed\n",
      "LOSS: 0.6042428016662598 ACCURCY: 0.6771870312339989\n",
      "current epoch 250 ,  50.0 % completed\n",
      "LOSS: 0.5735495090484619 ACCURCY: 0.6793886410650284\n",
      "current epoch 251 ,  50.2 % completed\n",
      "LOSS: 0.6021207571029663 ACCURCY: 0.6784180849974399\n",
      "current epoch 252 ,  50.4 % completed\n",
      "LOSS: 0.6045483946800232 ACCURCY: 0.6737966246799796\n",
      "current epoch 253 ,  50.6 % completed\n",
      "LOSS: 0.6164818406105042 ACCURCY: 0.6801892882744497\n",
      "current epoch 254 ,  50.8 % completed\n",
      "LOSS: 0.606349527835846 ACCURCY: 0.6742782181259601\n",
      "current epoch 255 ,  51.0 % completed\n",
      "LOSS: 0.5938170552253723 ACCURCY: 0.6757278279569893\n",
      "current epoch 256 ,  51.2 % completed\n",
      "LOSS: 0.5990620851516724 ACCURCY: 0.678737753200205\n",
      "current epoch 257 ,  51.4 % completed\n",
      "LOSS: 0.5863587260246277 ACCURCY: 0.679021603686636\n",
      "current epoch 258 ,  51.6 % completed\n",
      "LOSS: 0.5944574475288391 ACCURCY: 0.6790363256528419\n",
      "current epoch 259 ,  51.8 % completed\n",
      "LOSS: 0.5713111162185669 ACCURCY: 0.6727895709165385\n",
      "current epoch 260 ,  52.0 % completed\n",
      "LOSS: 0.5968936085700989 ACCURCY: 0.6801240102406554\n",
      "current epoch 261 ,  52.2 % completed\n",
      "LOSS: 0.5945042967796326 ACCURCY: 0.6797627158218126\n",
      "current epoch 262 ,  52.4 % completed\n",
      "LOSS: 0.5945396423339844 ACCURCY: 0.6782788817204302\n",
      "current epoch 263 ,  52.6 % completed\n",
      "LOSS: 0.6091471910476685 ACCURCY: 0.6789732718894008\n",
      "current epoch 264 ,  52.8 % completed\n",
      "LOSS: 0.6043818593025208 ACCURCY: 0.6789700686123912\n",
      "current epoch 265 ,  53.0 % completed\n",
      "LOSS: 0.6181549429893494 ACCURCY: 0.6771822345110087\n",
      "current epoch 266 ,  53.2 % completed\n",
      "LOSS: 0.5979213118553162 ACCURCY: 0.6698369237071172\n",
      "current epoch 267 ,  53.4 % completed\n",
      "LOSS: 0.6076070070266724 ACCURCY: 0.6760516620583717\n",
      "current epoch 268 ,  53.6 % completed\n",
      "LOSS: 0.597607433795929 ACCURCY: 0.6775486410650281\n",
      "current epoch 269 ,  53.8 % completed\n",
      "LOSS: 0.5848246812820435 ACCURCY: 0.6790132882744495\n",
      "current epoch 270 ,  54.0 % completed\n",
      "LOSS: 0.5801735520362854 ACCURCY: 0.6797457695852536\n",
      "current epoch 271 ,  54.2 % completed\n",
      "LOSS: 0.5902770161628723 ACCURCY: 0.6786529564772146\n",
      "current epoch 272 ,  54.4 % completed\n",
      "LOSS: 0.6118457913398743 ACCURCY: 0.6799726410650281\n",
      "current epoch 273 ,  54.6 % completed\n",
      "LOSS: 0.5753979086875916 ACCURCY: 0.6790222345110086\n",
      "current epoch 274 ,  54.8 % completed\n",
      "LOSS: 0.6023792028427124 ACCURCY: 0.67920208499744\n",
      "current epoch 275 ,  55.0 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.5976445078849792 ACCURCY: 0.6799736036866357\n",
      "current epoch 276 ,  55.2 % completed\n",
      "LOSS: 0.5971461534500122 ACCURCY: 0.6773099190988223\n",
      "current epoch 277 ,  55.4 % completed\n",
      "LOSS: 0.6015692353248596 ACCURCY: 0.6775969564772146\n",
      "current epoch 278 ,  55.6 % completed\n",
      "LOSS: 0.6014581918716431 ACCURCY: 0.6733006246799795\n",
      "current epoch 279 ,  55.8 % completed\n",
      "LOSS: 0.6174599528312683 ACCURCY: 0.677053271889401\n",
      "current epoch 280 ,  56.0 % completed\n",
      "LOSS: 0.6091575622558594 ACCURCY: 0.6788811059907834\n",
      "current epoch 281 ,  56.2 % completed\n",
      "LOSS: 0.6008443236351013 ACCURCY: 0.6765147158218126\n",
      "current epoch 282 ,  56.4 % completed\n",
      "LOSS: 0.5867465734481812 ACCURCY: 0.676179031233999\n",
      "current epoch 283 ,  56.6 % completed\n",
      "LOSS: 0.5818578600883484 ACCURCY: 0.6784683092677932\n",
      "current epoch 284 ,  56.8 % completed\n",
      "LOSS: 0.5893304347991943 ACCURCY: 0.679207844342038\n",
      "current epoch 285 ,  57.0 % completed\n",
      "LOSS: 0.5968725085258484 ACCURCY: 0.6750180686123913\n",
      "current epoch 286 ,  57.2 % completed\n",
      "LOSS: 0.5840814709663391 ACCURCY: 0.6804555289298516\n",
      "current epoch 287 ,  57.4 % completed\n",
      "LOSS: 0.5945913195610046 ACCURCY: 0.6797768069636457\n",
      "current epoch 288 ,  57.6 % completed\n",
      "LOSS: 0.605034589767456 ACCURCY: 0.6789921433691753\n",
      "current epoch 289 ,  57.8 % completed\n",
      "LOSS: 0.5804805755615234 ACCURCY: 0.6735460686123913\n",
      "current epoch 290 ,  58.0 % completed\n",
      "LOSS: 0.6085924506187439 ACCURCY: 0.6758961433691758\n",
      "current epoch 291 ,  58.2 % completed\n",
      "LOSS: 0.5988063812255859 ACCURCY: 0.6771076784434205\n",
      "current epoch 292 ,  58.4 % completed\n",
      "LOSS: 0.6042199730873108 ACCURCY: 0.6786916784434205\n",
      "current epoch 293 ,  58.6 % completed\n",
      "LOSS: 0.5971090793609619 ACCURCY: 0.6797691059907832\n",
      "current epoch 294 ,  58.8 % completed\n",
      "LOSS: 0.6043769717216492 ACCURCY: 0.6771284751664106\n",
      "current epoch 295 ,  59.0 % completed\n",
      "LOSS: 0.5804126858711243 ACCURCY: 0.6790804915514594\n",
      "current epoch 296 ,  59.2 % completed\n",
      "LOSS: 0.5855826735496521 ACCURCY: 0.6733511807475678\n",
      "current epoch 297 ,  59.4 % completed\n",
      "LOSS: 0.5950798392295837 ACCURCY: 0.6790052718894009\n",
      "current epoch 298 ,  59.6 % completed\n",
      "LOSS: 0.5843329429626465 ACCURCY: 0.6793796784434204\n",
      "current epoch 299 ,  59.8 % completed\n",
      "LOSS: 0.5900600552558899 ACCURCY: 0.6762926246799794\n",
      "current epoch 300 ,  60.0 % completed\n",
      "LOSS: 0.6046319603919983 ACCURCY: 0.6793489564772146\n",
      "current epoch 301 ,  60.2 % completed\n",
      "LOSS: 0.5894491672515869 ACCURCY: 0.6801848069636458\n",
      "current epoch 302 ,  60.4 % completed\n",
      "LOSS: 0.6178649067878723 ACCURCY: 0.6784443092677931\n",
      "current epoch 303 ,  60.6 % completed\n",
      "LOSS: 0.6239288449287415 ACCURCY: 0.6786331059907833\n",
      "current epoch 304 ,  60.8 % completed\n",
      "LOSS: 0.6008933782577515 ACCURCY: 0.678920790578597\n",
      "current epoch 305 ,  61.0 % completed\n",
      "LOSS: 0.5950185656547546 ACCURCY: 0.68070288172043\n",
      "current epoch 306 ,  61.2 % completed\n",
      "LOSS: 0.6045907139778137 ACCURCY: 0.6784471971326163\n",
      "current epoch 307 ,  61.4 % completed\n",
      "LOSS: 0.5691649317741394 ACCURCY: 0.6735546994367638\n",
      "current epoch 308 ,  61.6 % completed\n",
      "LOSS: 0.5999436378479004 ACCURCY: 0.6776081597542242\n",
      "current epoch 309 ,  61.8 % completed\n",
      "LOSS: 0.6150413155555725 ACCURCY: 0.6796977695852534\n",
      "current epoch 310 ,  62.0 % completed\n",
      "LOSS: 0.5973029136657715 ACCURCY: 0.6788459190988224\n",
      "current epoch 311 ,  62.2 % completed\n",
      "LOSS: 0.598659098148346 ACCURCY: 0.6768020849974399\n",
      "current epoch 312 ,  62.4 % completed\n",
      "LOSS: 0.5954176783561707 ACCURCY: 0.6766420686123911\n",
      "current epoch 313 ,  62.6 % completed\n",
      "LOSS: 0.60439532995224 ACCURCY: 0.6746683092677931\n",
      "current epoch 314 ,  62.8 % completed\n",
      "LOSS: 0.587018609046936 ACCURCY: 0.6801268981054786\n",
      "current epoch 315 ,  63.0 % completed\n",
      "LOSS: 0.5985431671142578 ACCURCY: 0.6779687905785969\n",
      "current epoch 316 ,  63.2 % completed\n",
      "LOSS: 0.6088658571243286 ACCURCY: 0.6808516784434204\n",
      "current epoch 317 ,  63.4 % completed\n",
      "LOSS: 0.6004654765129089 ACCURCY: 0.6802756784434204\n",
      "current epoch 318 ,  63.6 % completed\n",
      "LOSS: 0.6201483011245728 ACCURCY: 0.6769473466461855\n",
      "current epoch 319 ,  63.8 % completed\n",
      "LOSS: 0.6091863512992859 ACCURCY: 0.6797284751664106\n",
      "current epoch 320 ,  64.0 % completed\n",
      "LOSS: 0.6203641295433044 ACCURCY: 0.6769937532002049\n",
      "current epoch 321 ,  64.2 % completed\n",
      "LOSS: 0.607469379901886 ACCURCY: 0.6791339190988225\n",
      "current epoch 322 ,  64.4 % completed\n",
      "LOSS: 0.6030729413032532 ACCURCY: 0.6779115289298515\n",
      "current epoch 323 ,  64.6 % completed\n",
      "LOSS: 0.617233395576477 ACCURCY: 0.6789191971326163\n",
      "current epoch 324 ,  64.8 % completed\n",
      "LOSS: 0.5996558666229248 ACCURCY: 0.6760811059907832\n",
      "current epoch 325 ,  65.0 % completed\n",
      "LOSS: 0.598656415939331 ACCURCY: 0.6795156784434206\n",
      "current epoch 326 ,  65.2 % completed\n",
      "LOSS: 0.599910318851471 ACCURCY: 0.6793911971326163\n",
      "current epoch 327 ,  65.4 % completed\n",
      "LOSS: 0.5896652936935425 ACCURCY: 0.6722919774705582\n",
      "current epoch 328 ,  65.6 % completed\n",
      "LOSS: 0.5878521800041199 ACCURCY: 0.6791857532002049\n",
      "current epoch 329 ,  65.8 % completed\n",
      "LOSS: 0.5898194313049316 ACCURCY: 0.6791854377880184\n",
      "current epoch 330 ,  66.0 % completed\n",
      "LOSS: 0.5771112442016602 ACCURCY: 0.6749694214029698\n",
      "current epoch 331 ,  66.2 % completed\n",
      "LOSS: 0.5711700320243835 ACCURCY: 0.6768689564772145\n",
      "current epoch 332 ,  66.4 % completed\n",
      "LOSS: 0.5653596520423889 ACCURCY: 0.6761979190988224\n",
      "current epoch 333 ,  66.6 % completed\n",
      "LOSS: 0.6063673496246338 ACCURCY: 0.6789262345110088\n",
      "current epoch 334 ,  66.8 % completed\n",
      "LOSS: 0.6004497408866882 ACCURCY: 0.6764897368151561\n",
      "current epoch 335 ,  67.0 % completed\n",
      "LOSS: 0.5952199697494507 ACCURCY: 0.6764942345110088\n",
      "current epoch 336 ,  67.2 % completed\n",
      "LOSS: 0.6178576350212097 ACCURCY: 0.6712388489503328\n",
      "current epoch 337 ,  67.4 % completed\n",
      "LOSS: 0.5978924632072449 ACCURCY: 0.6684734050179212\n",
      "current epoch 338 ,  67.6 % completed\n",
      "LOSS: 0.5953245759010315 ACCURCY: 0.6802686410650282\n",
      "current epoch 339 ,  67.8 % completed\n",
      "LOSS: 0.5934385061264038 ACCURCY: 0.6800801597542242\n",
      "current epoch 340 ,  68.0 % completed\n",
      "LOSS: 0.590701699256897 ACCURCY: 0.6801694541730672\n",
      "current epoch 341 ,  68.2 % completed\n",
      "LOSS: 0.5967389941215515 ACCURCY: 0.6788302508960574\n",
      "current epoch 342 ,  68.4 % completed\n",
      "LOSS: 0.5896622538566589 ACCURCY: 0.6785643092677932\n",
      "current epoch 343 ,  68.6 % completed\n",
      "LOSS: 0.5916050672531128 ACCURCY: 0.6769454377880183\n",
      "current epoch 344 ,  68.8 % completed\n",
      "LOSS: 0.5873890519142151 ACCURCY: 0.6793713630312339\n",
      "current epoch 345 ,  69.0 % completed\n",
      "LOSS: 0.6113662123680115 ACCURCY: 0.6799467158218124\n",
      "current epoch 346 ,  69.2 % completed\n",
      "LOSS: 0.597950279712677 ACCURCY: 0.6797627158218126\n",
      "current epoch 347 ,  69.4 % completed\n",
      "LOSS: 0.590971052646637 ACCURCY: 0.6803313466461854\n",
      "current epoch 348 ,  69.6 % completed\n",
      "LOSS: 0.5820445418357849 ACCURCY: 0.6757185499231951\n",
      "current epoch 349 ,  69.8 % completed\n",
      "LOSS: 0.6088228821754456 ACCURCY: 0.6793227158218127\n",
      "current epoch 350 ,  70.0 % completed\n",
      "LOSS: 0.5852278470993042 ACCURCY: 0.6743630148489504\n",
      "current epoch 351 ,  70.2 % completed\n",
      "LOSS: 0.6044213175773621 ACCURCY: 0.6696250896057347\n",
      "current epoch 352 ,  70.4 % completed\n",
      "LOSS: 0.6033627986907959 ACCURCY: 0.6788961597542243\n",
      "current epoch 353 ,  70.6 % completed\n",
      "LOSS: 0.6056287884712219 ACCURCY: 0.67980208499744\n",
      "current epoch 354 ,  70.8 % completed\n",
      "LOSS: 0.6006293296813965 ACCURCY: 0.6755079938556069\n",
      "current epoch 355 ,  71.0 % completed\n",
      "LOSS: 0.5932080745697021 ACCURCY: 0.6752196620583719\n",
      "current epoch 356 ,  71.2 % completed\n",
      "LOSS: 0.5970950722694397 ACCURCY: 0.6794590476190477\n",
      "current epoch 357 ,  71.4 % completed\n",
      "LOSS: 0.6090843081474304 ACCURCY: 0.680005603686636\n",
      "current epoch 358 ,  71.6 % completed\n",
      "LOSS: 0.6018319725990295 ACCURCY: 0.6785684751664107\n",
      "current epoch 359 ,  71.8 % completed\n",
      "LOSS: 0.6084843277931213 ACCURCY: 0.678964309267793\n",
      "current epoch 360 ,  72.0 % completed\n",
      "LOSS: 0.5826122164726257 ACCURCY: 0.6771547158218126\n",
      "current epoch 361 ,  72.2 % completed\n",
      "LOSS: 0.5897484421730042 ACCURCY: 0.6796356784434205\n",
      "current epoch 362 ,  72.4 % completed\n",
      "LOSS: 0.5785109400749207 ACCURCY: 0.6752743840245775\n",
      "current epoch 363 ,  72.6 % completed\n",
      "LOSS: 0.6014673113822937 ACCURCY: 0.6798260849974398\n",
      "current epoch 364 ,  72.8 % completed\n",
      "LOSS: 0.612467885017395 ACCURCY: 0.6739652555043523\n",
      "current epoch 365 ,  73.0 % completed\n",
      "LOSS: 0.605926513671875 ACCURCY: 0.6797953466461855\n",
      "current epoch 366 ,  73.2 % completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.6352018117904663 ACCURCY: 0.6780577532002048\n",
      "current epoch 367 ,  73.4 % completed\n",
      "LOSS: 0.6056711077690125 ACCURCY: 0.6795326410650283\n",
      "current epoch 368 ,  73.6 % completed\n",
      "LOSS: 0.6171861290931702 ACCURCY: 0.6745050896057347\n",
      "current epoch 369 ,  73.8 % completed\n",
      "LOSS: 0.566402018070221 ACCURCY: 0.6747463840245775\n",
      "current epoch 370 ,  74.0 % completed\n",
      "LOSS: 0.6038865447044373 ACCURCY: 0.6782359938556068\n",
      "current epoch 371 ,  74.2 % completed\n",
      "LOSS: 0.6128408908843994 ACCURCY: 0.6804052882744496\n",
      "current epoch 372 ,  74.4 % completed\n",
      "LOSS: 0.5856325030326843 ACCURCY: 0.6793368069636457\n",
      "current epoch 373 ,  74.6 % completed\n",
      "LOSS: 0.6100407242774963 ACCURCY: 0.6783195125448028\n",
      "current epoch 374 ,  74.8 % completed\n",
      "LOSS: 0.6065163016319275 ACCURCY: 0.6740276620583718\n",
      "current epoch 375 ,  75.0 % completed\n",
      "LOSS: 0.5874571800231934 ACCURCY: 0.6768862345110087\n",
      "current epoch 376 ,  75.2 % completed\n",
      "LOSS: 0.6035345792770386 ACCURCY: 0.6794763256528418\n",
      "current epoch 377 ,  75.4 % completed\n",
      "LOSS: 0.6117475032806396 ACCURCY: 0.6792779027137738\n",
      "current epoch 378 ,  75.6 % completed\n",
      "LOSS: 0.5892384052276611 ACCURCY: 0.6802843256528418\n",
      "current epoch 379 ,  75.8 % completed\n",
      "LOSS: 0.6109838485717773 ACCURCY: 0.6743687905785969\n",
      "current epoch 380 ,  76.0 % completed\n",
      "LOSS: 0.6176745295524597 ACCURCY: 0.6747063840245775\n",
      "current epoch 381 ,  76.2 % completed\n",
      "LOSS: 0.599836528301239 ACCURCY: 0.6790673630312338\n",
      "current epoch 382 ,  76.4 % completed\n",
      "LOSS: 0.6004796028137207 ACCURCY: 0.672275330261137\n",
      "current epoch 383 ,  76.6 % completed\n",
      "LOSS: 0.5968142151832581 ACCURCY: 0.678149603686636\n",
      "current epoch 384 ,  76.8 % completed\n",
      "LOSS: 0.599755585193634 ACCURCY: 0.6763870312339989\n",
      "current epoch 385 ,  77.0 % completed\n",
      "LOSS: 0.6026377081871033 ACCURCY: 0.6786139027137738\n",
      "current epoch 386 ,  77.2 % completed\n",
      "LOSS: 0.6027584075927734 ACCURCY: 0.6813204915514594\n",
      "current epoch 387 ,  77.4 % completed\n",
      "LOSS: 0.5897178053855896 ACCURCY: 0.6795419190988224\n",
      "current epoch 388 ,  77.6 % completed\n",
      "LOSS: 0.57240891456604 ACCURCY: 0.6733284587813619\n",
      "current epoch 389 ,  77.8 % completed\n",
      "LOSS: 0.5788210034370422 ACCURCY: 0.6765332718894008\n",
      "current epoch 390 ,  78.0 % completed\n",
      "LOSS: 0.5849818587303162 ACCURCY: 0.6780126246799796\n",
      "current epoch 391 ,  78.2 % completed\n",
      "LOSS: 0.5898848176002502 ACCURCY: 0.68071088172043\n",
      "current epoch 392 ,  78.4 % completed\n",
      "LOSS: 0.6142788529396057 ACCURCY: 0.6797147322068612\n",
      "current epoch 393 ,  78.6 % completed\n",
      "LOSS: 0.5832604765892029 ACCURCY: 0.6794116784434204\n",
      "current epoch 394 ,  78.8 % completed\n",
      "LOSS: 0.5921801328659058 ACCURCY: 0.6789976036866358\n",
      "current epoch 395 ,  79.0 % completed\n",
      "LOSS: 0.6053984761238098 ACCURCY: 0.6797790476190475\n",
      "current epoch 396 ,  79.2 % completed\n",
      "LOSS: 0.6060912609100342 ACCURCY: 0.6789777532002048\n",
      "current epoch 397 ,  79.4 % completed\n",
      "LOSS: 0.6057021617889404 ACCURCY: 0.6800657695852536\n",
      "current epoch 398 ,  79.6 % completed\n",
      "LOSS: 0.5973161458969116 ACCURCY: 0.6779681597542244\n",
      "current epoch 399 ,  79.8 % completed\n",
      "LOSS: 0.5958324074745178 ACCURCY: 0.679133603686636\n",
      "current epoch 400 ,  80.0 % completed\n",
      "LOSS: 0.5982199907302856 ACCURCY: 0.6773275125448031\n",
      "current epoch 401 ,  80.2 % completed\n",
      "LOSS: 0.5956732630729675 ACCURCY: 0.6770478279569894\n",
      "current epoch 402 ,  80.4 % completed\n",
      "LOSS: 0.6016614437103271 ACCURCY: 0.6779431971326165\n",
      "current epoch 403 ,  80.6 % completed\n",
      "LOSS: 0.6030516624450684 ACCURCY: 0.6764958279569891\n",
      "current epoch 404 ,  80.8 % completed\n",
      "LOSS: 0.5963839292526245 ACCURCY: 0.6789531223758322\n",
      "current epoch 405 ,  81.0 % completed\n",
      "LOSS: 0.5951738357543945 ACCURCY: 0.6760756784434204\n",
      "current epoch 406 ,  81.2 % completed\n",
      "LOSS: 0.6034302711486816 ACCURCY: 0.6766948653353814\n",
      "current epoch 407 ,  81.4 % completed\n",
      "LOSS: 0.6066235899925232 ACCURCY: 0.6796039938556068\n",
      "current epoch 408 ,  81.6 % completed\n",
      "LOSS: 0.6079135537147522 ACCURCY: 0.6798539190988222\n",
      "current epoch 409 ,  81.8 % completed\n",
      "LOSS: 0.5994728803634644 ACCURCY: 0.6737230148489504\n",
      "current epoch 410 ,  82.0 % completed\n",
      "LOSS: 0.5942683219909668 ACCURCY: 0.675741886328725\n",
      "current epoch 411 ,  82.2 % completed\n",
      "LOSS: 0.602566659450531 ACCURCY: 0.6802414377880183\n",
      "current epoch 412 ,  82.4 % completed\n",
      "LOSS: 0.5939418077468872 ACCURCY: 0.6783089564772145\n",
      "current epoch 413 ,  82.6 % completed\n",
      "LOSS: 0.6098361611366272 ACCURCY: 0.6790673630312339\n",
      "current epoch 414 ,  82.8 % completed\n",
      "LOSS: 0.5983074307441711 ACCURCY: 0.6784750312339988\n",
      "current epoch 415 ,  83.0 % completed\n",
      "LOSS: 0.6060653924942017 ACCURCY: 0.6784583840245776\n",
      "current epoch 416 ,  83.2 % completed\n",
      "LOSS: 0.605639636516571 ACCURCY: 0.6791239938556067\n",
      "current epoch 417 ,  83.4 % completed\n",
      "FINISHED!!!\n",
      "LOSS: 0.5942500829696655 ACCURCY: 0.6768532718894009\n",
      "current epoch 418 ,  83.6 % completed\n"
     ]
    }
   ],
   "source": [
    "model1_trainingInfo = train(model1, criterion, train_loader, validation_loader, optimizer, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1852acf828>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = int(len(model1_trainingInfo[\"training_loss\"])/len(model1_trainingInfo[\"validation_accuracy\"]))\n",
    "plt.plot(model1_trainingInfo[\"training_loss\"][::steps], color = \"red\")\n",
    "plt.plot(model1_trainingInfo[\"validation_accuracy\"], color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_Model1(\n",
       "  (drop1): Dropout(p=0.1, inplace=False)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (channel1_l1): Linear(in_features=31, out_features=31, bias=True)\n",
       "  (channel1_l2): Linear(in_features=31, out_features=10, bias=True)\n",
       "  (channel1_l3): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (channel2_l1): Linear(in_features=31, out_features=31, bias=True)\n",
       "  (channel2_l2): Linear(in_features=31, out_features=10, bias=True)\n",
       "  (channel2_l3): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (out): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"models//model1_2018.pth\"\n",
    "torch.save(model1.state_dict(), path)\n",
    "model1.load_state_dict(torch.load(path))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carlos' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 31\n",
    "hidden1 = 31\n",
    "hidden2 = 10\n",
    "hidden3 = 5\n",
    "out_dim = 2\n",
    "\n",
    "modelCarlos = DNN_Carlos(input_dim, hidden1, hidden2, hidden3, out_dim)\n",
    "#model.to(\"cuda\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelCarlos.parameters(), lr=1e-4)\n",
    "\n",
    "training = TrainingData()\n",
    "testing = TestingData()\n",
    "train_loader = DataLoader(dataset = training, batch_size=2000, shuffle = True)\n",
    "validation_loader = DataLoader(dataset = testing, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainingInfo = trainMyModel(modelCarlos, criterion, train_loader, validation_loader, optimizer, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(len(model_trainingInfo[\"training_loss\"])/len(model_trainingInfo[\"validation_accuracy\"]))\n",
    "plt.plot(model_trainingInfo[\"training_loss\"][::steps], color = \"red\")\n",
    "plt.plot(model_trainingInfo[\"validation_accuracy\"], color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"models//modelCarlos_2018.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelCarlos.state_dict(), path)\n",
    "modelCarlos.load_state_dict(torch.load(path))\n",
    "modelCarlos.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
